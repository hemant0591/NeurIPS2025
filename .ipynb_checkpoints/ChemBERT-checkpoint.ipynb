{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e52b094-c711-424a-9939-a9eb6a415ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install /kaggle/input/rdkit-2025-3-3-cp311/rdkit-2025.3.3-cp311-cp311-manylinux_2_28_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12bfad66-0349-4aab-8f5e-53f3b6ddf7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from transformers import RobertaModel, RobertaTokenizer, get_linear_schedule_with_warmup\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "039a320c-7542-4007-bad8-c5bb015a1915",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c299d885-7dd6-4989-8534-08da391ad02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv('/kaggle/input/neurips-open-polymer-prediction-2025/train.csv')\n",
    "# test = pd.read_csv('/kaggle/input/neurips-open-polymer-prediction-2025/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdf2b604-80ad-45f7-aa4b-ba6de8069e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7973, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c7c697e-221d-48f6-9020-79f3bbe229e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Tg</th>\n",
       "      <th>FFV</th>\n",
       "      <th>Tc</th>\n",
       "      <th>Density</th>\n",
       "      <th>Rg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87817</td>\n",
       "      <td>*CC(*)c1ccccc1C(=O)OCCCCCC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.374645</td>\n",
       "      <td>0.205667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106919</td>\n",
       "      <td>*Nc1ccc([C@H](CCC)c2ccc(C3(c4ccc([C@@H](CCC)c5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.370410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>388772</td>\n",
       "      <td>*Oc1ccc(S(=O)(=O)c2ccc(Oc3ccc(C4(c5ccc(Oc6ccc(...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.378860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>519416</td>\n",
       "      <td>*Nc1ccc(-c2c(-c3ccc(C)cc3)c(-c3ccc(C)cc3)c(N*)...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.387324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539187</td>\n",
       "      <td>*Oc1ccc(OC(=O)c2cc(OCCCCCCCCCOCC3CCCN3c3ccc([N...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.355470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                             SMILES  Tg       FFV  \\\n",
       "0   87817                         *CC(*)c1ccccc1C(=O)OCCCCCC NaN  0.374645   \n",
       "1  106919  *Nc1ccc([C@H](CCC)c2ccc(C3(c4ccc([C@@H](CCC)c5... NaN  0.370410   \n",
       "2  388772  *Oc1ccc(S(=O)(=O)c2ccc(Oc3ccc(C4(c5ccc(Oc6ccc(... NaN  0.378860   \n",
       "3  519416  *Nc1ccc(-c2c(-c3ccc(C)cc3)c(-c3ccc(C)cc3)c(N*)... NaN  0.387324   \n",
       "4  539187  *Oc1ccc(OC(=O)c2cc(OCCCCCCCCCOCC3CCCN3c3ccc([N... NaN  0.355470   \n",
       "\n",
       "         Tc  Density  Rg  \n",
       "0  0.205667      NaN NaN  \n",
       "1       NaN      NaN NaN  \n",
       "2       NaN      NaN NaN  \n",
       "3       NaN      NaN NaN  \n",
       "4       NaN      NaN NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38a34c64-1cc0-418e-85ef-46efe75e494c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            0\n",
       "SMILES        0\n",
       "Tg         7462\n",
       "FFV         943\n",
       "Tc         7236\n",
       "Density    7360\n",
       "Rg         7359\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7698d04-79ca-4bae-958f-af726b1769c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Tg</th>\n",
       "      <th>FFV</th>\n",
       "      <th>Tc</th>\n",
       "      <th>Density</th>\n",
       "      <th>Rg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.973000e+03</td>\n",
       "      <td>7973</td>\n",
       "      <td>511.000000</td>\n",
       "      <td>7030.000000</td>\n",
       "      <td>737.000000</td>\n",
       "      <td>613.000000</td>\n",
       "      <td>614.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>*CC(*)c1ccccc1C(=O)OCCCCCC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.080050e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.452314</td>\n",
       "      <td>0.367212</td>\n",
       "      <td>0.256334</td>\n",
       "      <td>0.985484</td>\n",
       "      <td>16.419787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.218241e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111.228279</td>\n",
       "      <td>0.029609</td>\n",
       "      <td>0.089538</td>\n",
       "      <td>0.146189</td>\n",
       "      <td>4.608640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.781700e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-148.029738</td>\n",
       "      <td>0.226992</td>\n",
       "      <td>0.046500</td>\n",
       "      <td>0.748691</td>\n",
       "      <td>9.728355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.376641e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.674509</td>\n",
       "      <td>0.349549</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.890243</td>\n",
       "      <td>12.540328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.079079e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.040183</td>\n",
       "      <td>0.364264</td>\n",
       "      <td>0.236000</td>\n",
       "      <td>0.948193</td>\n",
       "      <td>15.052194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.621708e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161.147595</td>\n",
       "      <td>0.380790</td>\n",
       "      <td>0.330500</td>\n",
       "      <td>1.062096</td>\n",
       "      <td>20.411067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.147438e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>472.250000</td>\n",
       "      <td>0.777097</td>\n",
       "      <td>0.524000</td>\n",
       "      <td>1.840999</td>\n",
       "      <td>34.672906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                      SMILES          Tg          FFV  \\\n",
       "count   7.973000e+03                        7973  511.000000  7030.000000   \n",
       "unique           NaN                        7973         NaN          NaN   \n",
       "top              NaN  *CC(*)c1ccccc1C(=O)OCCCCCC         NaN          NaN   \n",
       "freq             NaN                           1         NaN          NaN   \n",
       "mean    1.080050e+09                         NaN   96.452314     0.367212   \n",
       "std     6.218241e+08                         NaN  111.228279     0.029609   \n",
       "min     8.781700e+04                         NaN -148.029738     0.226992   \n",
       "25%     5.376641e+08                         NaN   13.674509     0.349549   \n",
       "50%     1.079079e+09                         NaN   74.040183     0.364264   \n",
       "75%     1.621708e+09                         NaN  161.147595     0.380790   \n",
       "max     2.147438e+09                         NaN  472.250000     0.777097   \n",
       "\n",
       "                Tc     Density          Rg  \n",
       "count   737.000000  613.000000  614.000000  \n",
       "unique         NaN         NaN         NaN  \n",
       "top            NaN         NaN         NaN  \n",
       "freq           NaN         NaN         NaN  \n",
       "mean      0.256334    0.985484   16.419787  \n",
       "std       0.089538    0.146189    4.608640  \n",
       "min       0.046500    0.748691    9.728355  \n",
       "25%       0.186000    0.890243   12.540328  \n",
       "50%       0.236000    0.948193   15.052194  \n",
       "75%       0.330500    1.062096   20.411067  \n",
       "max       0.524000    1.840999   34.672906  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cba4416-4b32-412e-a500-79d858349c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tg         7462\n",
       "FFV         943\n",
       "Tc         7236\n",
       "Density    7360\n",
       "Rg         7359\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = train_df.isnull().sum()[['Tg', 'FFV', 'Tc', 'Density', 'Rg']]\n",
    "missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2107c8-0431-4534-bddc-263153c148a5",
   "metadata": {},
   "source": [
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "401d148a-b028-40bc-beb0-557913c5f52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChemBERTDS(Dataset):\n",
    "    def __init__(self, df, tokenizer, targ_col=None, max_len=None):\n",
    "        self.smiles = df['SMILES'].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        if max_len is None:\n",
    "            self.max_len = tokenizer.model_max_length\n",
    "        else:\n",
    "            self.max_len = max_len\n",
    "        self.has_target = targ_col is not None\n",
    "        if self.has_target:\n",
    "            self.target = df[targ_col].values.astype('float32')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.smiles)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            self.smiles[idx],\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        items = {k:v.squeeze(0) for k, v in encoding.items()}\n",
    "        if self.has_target:\n",
    "            items['target'] = torch.tensor(self.target[idx])\n",
    "        \n",
    "        return items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16408336-baf1-4941-a6d9-b3d8db7a898a",
   "metadata": {},
   "source": [
    "### Writing model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e36e5278-2ac1-42c5-9108-696ffa356b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class chemBERTModel(nn.Module):\n",
    "    def __init__(self, base_model, out_dim=1):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.regressor = nn.Linear(base_model.config.hidden_size, out_dim)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_tokens = outputs.last_hidden_state[:,0]\n",
    "        return self.regressor(self.dropout(cls_tokens)).squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb807b33-a77a-4159-8395-d3938689d087",
   "metadata": {},
   "source": [
    "### Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34984de0-4174-4218-ae62-184878ffac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dl, loss_fn, opt, sched):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    n = 0\n",
    "    for batch in dl:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        targets = batch['target'].to(device)\n",
    "        preds = model(input_ids, attention_mask)\n",
    "        loss = loss_fn(preds, targets)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        sched.step()\n",
    "        opt.zero_grad()\n",
    "        total_loss += loss.item() * len(targets)\n",
    "        n += len(targets)\n",
    "    return total_loss / n\n",
    "\n",
    "def eval(model, dl, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss, n = 0, 0\n",
    "    all_preds, all_targs = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in dl:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            targets = batch['target'].to(device)\n",
    "            preds = model(input_ids, attention_mask)\n",
    "            loss = loss_fn(preds, targets)\n",
    "            total_loss += loss.item() * len(targets)\n",
    "            n += len(targets)\n",
    "            all_preds.extend(preds.detach().cpu().numpy())\n",
    "            all_targs.extend(targets.detach().cpu().numpy())\n",
    "    return total_loss / n, all_preds, all_targs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afffa0ec-1c81-4c3a-ab66-7998b44f27a6",
   "metadata": {},
   "source": [
    "### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7463c4ba-1980-4584-858f-8ef0bc811f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_chemberta(df, target, base_model, tokenizer, n_epochs=30, save_dir = 'saved_models_chemberta', patience=5):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    df_clean = df[['SMILES', target]].dropna()\n",
    "        \n",
    "    # scale target\n",
    "    y_scaler = StandardScaler()\n",
    "    df_clean[target] = y_scaler.fit_transform(df_clean[[target]])\n",
    "    \n",
    "    # save scaler\n",
    "    with open(os.path.join(save_dir, f\"{target}_scaler.pkl\"), 'wb') as f:\n",
    "        pickle.dump(y_scaler, f)\n",
    "        \n",
    "    train_data, val_data = train_test_split(df_clean, test_size=0.2, random_state=42)\n",
    "    train_ds = ChemBERTDS(train_data, tokenizer, target)\n",
    "    val_ds = ChemBERTDS(val_data, tokenizer, target)\n",
    "    train_dl = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "    val_dl = DataLoader(val_ds, batch_size=16, shuffle=False)\n",
    "    \n",
    "    model = chemBERTModel(base_model).to(device)\n",
    "    opt = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        opt,\n",
    "        num_warmup_steps=int(0.1 * len(train_dl) * n_epochs),\n",
    "        num_training_steps=len(train_dl) * n_epochs\n",
    "    )\n",
    "    loss_fn = nn.L1Loss()\n",
    "    \n",
    "    best_val_loss = float(\"inf\")\n",
    "    epoch_no_improve = 0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = train(model, train_dl, loss_fn, opt, scheduler)\n",
    "        val_loss, preds, targs = eval(model, val_dl, loss_fn)\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs} | Train MAE: {train_loss:.4f}, Val MAE: {val_loss:.4f}\")\n",
    "        \n",
    "        if val_loss <= best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), os.path.join(save_dir, f\"{target}_model.pt\"))\n",
    "            epoch_no_improve = 0\n",
    "        else:\n",
    "            epoch_no_improve += 1\n",
    "            if epoch_no_improve >= patience:\n",
    "                print(\"Early stopping triggered!\")\n",
    "                break\n",
    "        \n",
    "    model.load_state_dict(torch.load(os.path.join(save_dir, f\"{target}_model.pt\")))\n",
    "    \n",
    "    # Free up memory\n",
    "    # del train_dl, val_dl, opt, scheduler\n",
    "    # torch.cuda.empty_cache()\n",
    "    # gc.collect()\n",
    "    \n",
    "    return model, tokenizer, y_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "537df94b-d1ce-4210-aaa6-1b7aa2eeb7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_chemberta(df, target, model, tokenizer, scaler):\n",
    "    test_ds = ChemBERTDS(df, tokenizer)\n",
    "    test_loader = DataLoader(test_ds, batch_size=16, shuffle=False)\n",
    "    \n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            preds.extend(outputs.detach().cpu().numpy())\n",
    "    preds = scaler.inverse_transform(np.array(preds).reshape(-1, 1)).flatten()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "545233f9-a64b-4330-a7a2-fccf5fac24a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"seyonec/ChemBERTa-zinc-base-v1\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "targets = ['Tg', 'FFV', 'Tc', 'Density', 'Rg']\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "for target in targets:\n",
    "    print(f'Working on predicting: {target}')\n",
    "    \n",
    "    base_model = RobertaModel.from_pretrained(MODEL_NAME)\n",
    "    \n",
    "    model, tokenizer, y_scaler = train_chemberta(\n",
    "        df=train_df, \n",
    "        target=target, \n",
    "        base_model=base_model, \n",
    "        tokenizer=tokenizer)\n",
    "    \n",
    "    test_df[target_col] = predict_chemberta(\n",
    "        df=test_df, \n",
    "        target=target, \n",
    "        model=model, \n",
    "        tokenizer=tokenizer, \n",
    "        scaler=y_scaler\n",
    "    )\n",
    "    \n",
    "    # Clean up to be safe\n",
    "    del model, base_model, y_scaler\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0426964f-cf74-4884-933a-48ff39baf044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 | Train MAE: 0.8943, Val MAE: 0.6919\n",
      "Epoch 2/30 | Train MAE: 0.7500, Val MAE: 0.6409\n",
      "Epoch 3/30 | Train MAE: 0.6698, Val MAE: 0.5810\n",
      "Epoch 4/30 | Train MAE: 0.5999, Val MAE: 0.5775\n",
      "Epoch 5/30 | Train MAE: 0.5657, Val MAE: 0.6090\n",
      "Epoch 6/30 | Train MAE: 0.5259, Val MAE: 0.5221\n",
      "Epoch 7/30 | Train MAE: 0.4592, Val MAE: 0.6000\n",
      "Epoch 8/30 | Train MAE: 0.4438, Val MAE: 0.5490\n",
      "Epoch 9/30 | Train MAE: 0.4569, Val MAE: 0.5878\n",
      "Epoch 10/30 | Train MAE: 0.4427, Val MAE: 0.5472\n",
      "Epoch 11/30 | Train MAE: 0.3995, Val MAE: 0.6170\n",
      "Early stopping triggered!\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer, y_scaler = train_chemberta(train_df, 'Tg', base_model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef89899a-9987-4115-8ba5-51d7ec50a9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Tg'] = predict_chemberta(test_df, 'Tg', model, tokenizer, y_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11344fe5-c98b-4ac7-afef-722c966fe17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 | Train MAE: 0.6394, Val MAE: 0.4840\n",
      "Epoch 2/30 | Train MAE: 0.4991, Val MAE: 0.3891\n",
      "Epoch 3/30 | Train MAE: 0.4230, Val MAE: 0.3690\n",
      "Epoch 4/30 | Train MAE: 0.3627, Val MAE: 0.3696\n",
      "Epoch 5/30 | Train MAE: 0.3242, Val MAE: 0.2978\n",
      "Epoch 6/30 | Train MAE: 0.2810, Val MAE: 0.2765\n",
      "Epoch 7/30 | Train MAE: 0.2647, Val MAE: 0.2782\n",
      "Epoch 8/30 | Train MAE: 0.2432, Val MAE: 0.2502\n",
      "Epoch 9/30 | Train MAE: 0.2202, Val MAE: 0.2835\n",
      "Epoch 10/30 | Train MAE: 0.2097, Val MAE: 0.2460\n",
      "Epoch 11/30 | Train MAE: 0.2005, Val MAE: 0.2238\n",
      "Epoch 12/30 | Train MAE: 0.1879, Val MAE: 0.2264\n",
      "Epoch 13/30 | Train MAE: 0.1759, Val MAE: 0.2413\n",
      "Epoch 14/30 | Train MAE: 0.1724, Val MAE: 0.2096\n",
      "Epoch 15/30 | Train MAE: 0.1655, Val MAE: 0.2298\n",
      "Epoch 16/30 | Train MAE: 0.1569, Val MAE: 0.2403\n",
      "Epoch 17/30 | Train MAE: 0.1520, Val MAE: 0.2049\n",
      "Epoch 18/30 | Train MAE: 0.1468, Val MAE: 0.2186\n",
      "Epoch 19/30 | Train MAE: 0.1410, Val MAE: 0.2057\n",
      "Epoch 20/30 | Train MAE: 0.1367, Val MAE: 0.2106\n",
      "Epoch 21/30 | Train MAE: 0.1314, Val MAE: 0.2001\n",
      "Epoch 22/30 | Train MAE: 0.1304, Val MAE: 0.2053\n",
      "Epoch 23/30 | Train MAE: 0.1279, Val MAE: 0.2221\n",
      "Epoch 24/30 | Train MAE: 0.1262, Val MAE: 0.2003\n",
      "Epoch 25/30 | Train MAE: 0.1173, Val MAE: 0.2054\n",
      "Epoch 26/30 | Train MAE: 0.1157, Val MAE: 0.2002\n",
      "Early stopping triggered!\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer, y_scaler = train_chemberta(train_df, 'FFV', base_model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c78be161-0e0d-48fc-ad43-2b2919f6e4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['FFV'] = predict_chemberta(test_df, 'FFV', model, tokenizer, y_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3b4ba13-879c-4759-8e65-ca6322cd96d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 | Train MAE: 0.9367, Val MAE: 0.7300\n",
      "Epoch 2/30 | Train MAE: 0.5929, Val MAE: 0.3859\n",
      "Epoch 3/30 | Train MAE: 0.4447, Val MAE: 0.3686\n",
      "Epoch 4/30 | Train MAE: 0.4226, Val MAE: 0.3340\n",
      "Epoch 5/30 | Train MAE: 0.3915, Val MAE: 0.3288\n",
      "Epoch 6/30 | Train MAE: 0.3783, Val MAE: 0.3665\n",
      "Epoch 7/30 | Train MAE: 0.3776, Val MAE: 0.3508\n",
      "Epoch 8/30 | Train MAE: 0.3780, Val MAE: 0.3138\n",
      "Epoch 9/30 | Train MAE: 0.3540, Val MAE: 0.3402\n",
      "Epoch 10/30 | Train MAE: 0.3499, Val MAE: 0.3560\n",
      "Epoch 11/30 | Train MAE: 0.3185, Val MAE: 0.3478\n",
      "Epoch 12/30 | Train MAE: 0.3230, Val MAE: 0.3603\n",
      "Epoch 13/30 | Train MAE: 0.3167, Val MAE: 0.3279\n",
      "Early stopping triggered!\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer, y_scaler = train_chemberta(train_df, 'Tc', base_model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "615d46c2-bc44-42ce-bb53-7e05ea35d53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Tc'] = predict_chemberta(test_df, 'Tc', model, tokenizer, y_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66261881-b40c-47ce-ba3e-e7c114cf8a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 | Train MAE: 0.8395, Val MAE: 0.6220\n",
      "Epoch 2/30 | Train MAE: 0.6100, Val MAE: 0.4561\n",
      "Epoch 3/30 | Train MAE: 0.4625, Val MAE: 0.3691\n",
      "Epoch 4/30 | Train MAE: 0.4030, Val MAE: 0.3368\n",
      "Epoch 5/30 | Train MAE: 0.3796, Val MAE: 0.3537\n",
      "Epoch 6/30 | Train MAE: 0.3472, Val MAE: 0.2956\n",
      "Epoch 7/30 | Train MAE: 0.3462, Val MAE: 0.3429\n",
      "Epoch 8/30 | Train MAE: 0.3271, Val MAE: 0.3066\n",
      "Epoch 9/30 | Train MAE: 0.3131, Val MAE: 0.3111\n",
      "Epoch 10/30 | Train MAE: 0.3046, Val MAE: 0.3025\n",
      "Epoch 11/30 | Train MAE: 0.2939, Val MAE: 0.3168\n",
      "Early stopping triggered!\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer, y_scaler = train_chemberta(train_df, 'Density', base_model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b672e612-1d7e-49a7-a7bd-824991aec0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Density'] = predict_chemberta(test_df, 'Density', model, tokenizer, y_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df6295dd-3cd0-49a5-b144-016ed6d61fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 | Train MAE: 0.8712, Val MAE: 0.7677\n",
      "Epoch 2/30 | Train MAE: 0.6407, Val MAE: 0.5080\n",
      "Epoch 3/30 | Train MAE: 0.5103, Val MAE: 0.3847\n",
      "Epoch 4/30 | Train MAE: 0.4704, Val MAE: 0.3789\n",
      "Epoch 5/30 | Train MAE: 0.4330, Val MAE: 0.3794\n",
      "Epoch 6/30 | Train MAE: 0.4247, Val MAE: 0.4003\n",
      "Epoch 7/30 | Train MAE: 0.3658, Val MAE: 0.3727\n",
      "Epoch 8/30 | Train MAE: 0.3612, Val MAE: 0.3631\n",
      "Epoch 9/30 | Train MAE: 0.3624, Val MAE: 0.3807\n",
      "Epoch 10/30 | Train MAE: 0.3350, Val MAE: 0.3660\n",
      "Epoch 11/30 | Train MAE: 0.3337, Val MAE: 0.3836\n",
      "Epoch 12/30 | Train MAE: 0.3304, Val MAE: 0.3732\n",
      "Epoch 13/30 | Train MAE: 0.3032, Val MAE: 0.3764\n",
      "Early stopping triggered!\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer, y_scaler = train_chemberta(train_df, 'Rg', base_model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27ec7437-9819-446f-83bf-d15d21a0fa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Rg'] = predict_chemberta(test_df, 'Rg', model, tokenizer, y_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62858d6b-73d7-4df1-87e4-be05cf67d96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Tg</th>\n",
       "      <th>FFV</th>\n",
       "      <th>Tc</th>\n",
       "      <th>Density</th>\n",
       "      <th>Rg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1109053969</td>\n",
       "      <td>*Oc1ccc(C=NN=Cc2ccc(Oc3ccc(C(c4ccc(*)cc4)(C(F)...</td>\n",
       "      <td>111.223137</td>\n",
       "      <td>0.367491</td>\n",
       "      <td>0.225861</td>\n",
       "      <td>1.163119</td>\n",
       "      <td>20.589508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1422188626</td>\n",
       "      <td>*Oc1ccc(C(C)(C)c2ccc(Oc3ccc(C(=O)c4cccc(C(=O)c...</td>\n",
       "      <td>231.585541</td>\n",
       "      <td>0.377434</td>\n",
       "      <td>0.223918</td>\n",
       "      <td>1.110826</td>\n",
       "      <td>19.536264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2032016830</td>\n",
       "      <td>*c1cccc(OCCCCCCCCOc2cccc(N3C(=O)c4ccc(-c5cccc6...</td>\n",
       "      <td>273.134460</td>\n",
       "      <td>0.346256</td>\n",
       "      <td>0.255565</td>\n",
       "      <td>1.098610</td>\n",
       "      <td>19.572638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                             SMILES          Tg  \\\n",
       "0  1109053969  *Oc1ccc(C=NN=Cc2ccc(Oc3ccc(C(c4ccc(*)cc4)(C(F)...  111.223137   \n",
       "1  1422188626  *Oc1ccc(C(C)(C)c2ccc(Oc3ccc(C(=O)c4cccc(C(=O)c...  231.585541   \n",
       "2  2032016830  *c1cccc(OCCCCCCCCOc2cccc(N3C(=O)c4ccc(-c5cccc6...  273.134460   \n",
       "\n",
       "        FFV        Tc   Density         Rg  \n",
       "0  0.367491  0.225861  1.163119  20.589508  \n",
       "1  0.377434  0.223918  1.110826  19.536264  \n",
       "2  0.346256  0.255565  1.098610  19.572638  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48d55ac4-a4b0-488d-b87d-940a719aa77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    7973.000000\n",
      "mean       40.538819\n",
      "std        25.570449\n",
      "min         3.000000\n",
      "25%        21.000000\n",
      "50%        35.000000\n",
      "75%        54.000000\n",
      "max       238.000000\n",
      "Name: SMILES, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# lengths = train_df['SMILES'].apply(lambda x: len(tokenizer.tokenize(x)))\n",
    "# print(lengths.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb6aec4-2fbc-4200-b62a-2263fd64cd67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
