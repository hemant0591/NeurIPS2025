{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-12T08:21:16.336689Z",
     "iopub.status.busy": "2025-07-12T08:21:16.336465Z",
     "iopub.status.idle": "2025-07-12T08:21:19.493771Z",
     "shell.execute_reply": "2025-07-12T08:21:19.492857Z",
     "shell.execute_reply.started": "2025-07-12T08:21:16.336672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/rdkit-2025-3-3-cp311/rdkit-2025.3.3-cp311-cp311-manylinux_2_28_x86_64.whl\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit==2025.3.3) (1.26.4)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit==2025.3.3) (11.2.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rdkit==2025.3.3) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rdkit==2025.3.3) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rdkit==2025.3.3) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rdkit==2025.3.3) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rdkit==2025.3.3) (2024.2.0)\n",
      "rdkit is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/rdkit-2025-3-3-cp311/rdkit-2025.3.3-cp311-cp311-manylinux_2_28_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T08:21:19.494954Z",
     "iopub.status.busy": "2025-07-12T08:21:19.494695Z",
     "iopub.status.idle": "2025-07-12T08:21:22.656947Z",
     "shell.execute_reply": "2025-07-12T08:21:22.656365Z",
     "shell.execute_reply.started": "2025-07-12T08:21:19.494927Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor,ExtraTreesRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split, GroupKFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import rdmolops\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.rdFingerprintGenerator import GetMorganGenerator\n",
    "\n",
    "import xgboost as xgb\n",
    "import torch\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T08:21:22.658657Z",
     "iopub.status.busy": "2025-07-12T08:21:22.657707Z",
     "iopub.status.idle": "2025-07-12T08:21:22.694036Z",
     "shell.execute_reply": "2025-07-12T08:21:22.693236Z",
     "shell.execute_reply.started": "2025-07-12T08:21:22.658631Z"
    }
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    TARGETS = ['Tg', 'FFV', 'Tc', 'Density', 'Rg']\n",
    "    SEED = 42\n",
    "    FOLDS = 5\n",
    "\n",
    "    # Optimization settings\n",
    "    N_TRIALS = 100  # Optuna trials per target\n",
    "    EARLY_STOPPING = 100\n",
    "    MAX_ITERATIONS = 5000\n",
    "    \n",
    "    # Model settings\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T08:21:22.695252Z",
     "iopub.status.busy": "2025-07-12T08:21:22.694973Z",
     "iopub.status.idle": "2025-07-12T08:21:22.713095Z",
     "shell.execute_reply": "2025-07-12T08:21:22.712442Z",
     "shell.execute_reply.started": "2025-07-12T08:21:22.695225Z"
    }
   },
   "outputs": [],
   "source": [
    "useless_cols = [   \n",
    "    \n",
    "    'MaxPartialCharge', \n",
    "    # Nan data\n",
    "    'BCUT2D_MWHI',\n",
    "    'BCUT2D_MWLOW',\n",
    "    'BCUT2D_CHGHI',\n",
    "    'BCUT2D_CHGLO',\n",
    "    'BCUT2D_LOGPHI',\n",
    "    'BCUT2D_LOGPLOW',\n",
    "    'BCUT2D_MRHI',\n",
    "    'BCUT2D_MRLOW',\n",
    "\n",
    "    # Constant data\n",
    "    'NumRadicalElectrons',\n",
    "    'SMR_VSA8',\n",
    "    'SlogP_VSA9',\n",
    "    'fr_barbitur',\n",
    "    'fr_benzodiazepine',\n",
    "    'fr_dihydropyridine',\n",
    "    'fr_epoxide',\n",
    "    'fr_isothiocyan',\n",
    "    'fr_lactam',\n",
    "    'fr_nitroso',\n",
    "    'fr_prisulfonamd',\n",
    "    'fr_thiocyan',\n",
    "\n",
    "    # High correlated data >0.95\n",
    "    'MaxEStateIndex',\n",
    "    'HeavyAtomMolWt',\n",
    "    'ExactMolWt',\n",
    "    'NumValenceElectrons',\n",
    "    'Chi0',\n",
    "    'Chi0n',\n",
    "    'Chi0v',\n",
    "    'Chi1',\n",
    "    'Chi1n',\n",
    "    'Chi1v',\n",
    "    'Chi2n',\n",
    "    'Kappa1',\n",
    "    'LabuteASA',\n",
    "    'HeavyAtomCount',\n",
    "    'MolMR',\n",
    "    'Chi3n',\n",
    "    'BertzCT',\n",
    "    'Chi2v',\n",
    "    'Chi4n',\n",
    "    'HallKierAlpha',\n",
    "    'Chi3v',\n",
    "    'Chi4v',\n",
    "    'MinAbsPartialCharge',\n",
    "    'MinPartialCharge',\n",
    "    'MaxAbsPartialCharge',\n",
    "    'FpDensityMorgan2',\n",
    "    'FpDensityMorgan3',\n",
    "    'Phi',\n",
    "    'Kappa3',\n",
    "    'fr_nitrile',\n",
    "    'SlogP_VSA6',\n",
    "    'NumAromaticCarbocycles',\n",
    "    'NumAromaticRings',\n",
    "    'fr_benzene',\n",
    "    'VSA_EState6',\n",
    "    'NOCount',\n",
    "    'fr_C_O',\n",
    "    'fr_C_O_noCOO',\n",
    "    'NumHDonors',\n",
    "    'fr_amide',\n",
    "    'fr_Nhpyrrole',\n",
    "    'fr_phenol',\n",
    "    'fr_phenol_noOrthoHbond',\n",
    "    'fr_COO2',\n",
    "    'fr_halogen',\n",
    "    'fr_diazo',\n",
    "    'fr_nitro_arom',\n",
    "    'fr_phos_ester'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T08:21:22.714004Z",
     "iopub.status.busy": "2025-07-12T08:21:22.713785Z",
     "iopub.status.idle": "2025-07-12T08:21:22.731578Z",
     "shell.execute_reply": "2025-07-12T08:21:22.730989Z",
     "shell.execute_reply.started": "2025-07-12T08:21:22.713989Z"
    }
   },
   "outputs": [],
   "source": [
    "MINMAX_DICT = {\n",
    "    'Tg': [-148.0297376, 472.25],\n",
    "    'FFV': [0.2269924, 0.77709707], \n",
    "    'Tc': [0.0465, 0.524],\n",
    "    'Density': [0.748691234, 1.840998909],\n",
    "    'Rg': [9.7283551, 34.672905605],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Main Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T08:21:22.734157Z",
     "iopub.status.busy": "2025-07-12T08:21:22.733961Z",
     "iopub.status.idle": "2025-07-12T08:21:22.767576Z",
     "shell.execute_reply": "2025-07-12T08:21:22.767091Z",
     "shell.execute_reply.started": "2025-07-12T08:21:22.734141Z"
    }
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('/kaggle/input/neurips-open-polymer-prediction-2025/train.csv')\n",
    "test=pd.read_csv('/kaggle/input/neurips-open-polymer-prediction-2025/test.csv')\n",
    "ss=pd.read_csv('/kaggle/input/neurips-open-polymer-prediction-2025/sample_submission.csv')\n",
    "ID=test['id'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Extra Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T08:21:22.768431Z",
     "iopub.status.busy": "2025-07-12T08:21:22.768252Z",
     "iopub.status.idle": "2025-07-12T08:21:23.021238Z",
     "shell.execute_reply": "2025-07-12T08:21:23.020377Z",
     "shell.execute_reply.started": "2025-07-12T08:21:22.768416Z"
    }
   },
   "outputs": [],
   "source": [
    "tc_smiles = pd.read_csv('/kaggle/input/tc-smiles/Tc_SMILES.csv')\n",
    "tgss_smiles = pd.read_csv('/kaggle/input/tg-smiles-pid-polymer-class/TgSS_enriched_cleaned.csv')\n",
    "tg_smiles =pd.read_csv('/kaggle/input/smiles-extra-data/JCIM_sup_bigsmiles.csv')\n",
    "ktg_smiles =pd.read_excel('/kaggle/input/smiles-extra-data/data_tg3.xlsx')\n",
    "de_smiles =pd.read_excel('/kaggle/input/smiles-extra-data/data_dnst1.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T05:31:53.317447Z",
     "iopub.status.busy": "2025-07-12T05:31:53.317109Z",
     "iopub.status.idle": "2025-07-12T05:31:53.321755Z",
     "shell.execute_reply": "2025-07-12T05:31:53.320780Z",
     "shell.execute_reply.started": "2025-07-12T05:31:53.317424Z"
    }
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T08:21:23.022565Z",
     "iopub.status.busy": "2025-07-12T08:21:23.022192Z",
     "iopub.status.idle": "2025-07-12T08:21:23.027914Z",
     "shell.execute_reply": "2025-07-12T08:21:23.027049Z",
     "shell.execute_reply.started": "2025-07-12T08:21:23.022545Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_and_validate_smiles(smiles):\n",
    "    if not isinstance(smiles, str) or len(smiles) == 0:\n",
    "        return None\n",
    "\n",
    "    bad_patterns = [\n",
    "        '[R]', '[R1]', '[R2]', '[R3]', '[R4]', '[R5]', \n",
    "        \"[R']\", '[R\"]', 'R1', 'R2', 'R3', 'R4', 'R5',\n",
    "        # Additional patterns that cause issues\n",
    "        '([R])', '([R1])', '([R2])', \n",
    "    ]\n",
    "\n",
    "    for pattern in bad_patterns:\n",
    "        if pattern in smiles:\n",
    "            return None\n",
    "\n",
    "    if '][' in smiles and any(x in smiles for x in ['[R', 'R]']):\n",
    "        return None\n",
    "\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    \n",
    "    if mol is not None:\n",
    "        return Chem.MolToSmiles(mol, canonical=True)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T08:21:23.028910Z",
     "iopub.status.busy": "2025-07-12T08:21:23.028687Z",
     "iopub.status.idle": "2025-07-12T08:21:26.474186Z",
     "shell.execute_reply": "2025-07-12T08:21:26.473449Z",
     "shell.execute_reply.started": "2025-07-12T08:21:23.028886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples before cleaning 7973\n",
      "Test samples before cleaning 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7973/7973 [00:03<00:00, 2331.95it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1508.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples after cleaning 7973\n",
      "Test samples after cleaning 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train samples before cleaning {len(train['SMILES'].notnull())}\")\n",
    "print(f\"Test samples before cleaning {len(test['SMILES'].notnull())}\")\n",
    "train['SMILES'] = train['SMILES'].progress_apply(lambda s: clean_and_validate_smiles(s))\n",
    "test['SMILES'] = test['SMILES'].progress_apply(lambda s: clean_and_validate_smiles(s))\n",
    "print(f\"Train samples after cleaning {len(train['SMILES'].notnull())}\")\n",
    "print(f\"Test samples after cleaning {len(test['SMILES'].notnull())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T08:21:26.475221Z",
     "iopub.status.busy": "2025-07-12T08:21:26.474967Z",
     "iopub.status.idle": "2025-07-12T08:21:26.480237Z",
     "shell.execute_reply": "2025-07-12T08:21:26.479588Z",
     "shell.execute_reply.started": "2025-07-12T08:21:26.475196Z"
    }
   },
   "outputs": [],
   "source": [
    "# we don't need to make changes to the tgss df\n",
    "\n",
    "ktg_smiles.rename(columns={'Tg [K]': 'Tg'}, inplace=True)\n",
    "tg_smiles.rename(columns={'Tg (C)': 'Tg'}, inplace=True)\n",
    "tc_smiles.rename(columns={'TC_mean': 'Tc'}, inplace=True)\n",
    "de_smiles.rename(columns={'density(g/cm3)': 'Density'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T08:21:26.481104Z",
     "iopub.status.busy": "2025-07-12T08:21:26.480856Z",
     "iopub.status.idle": "2025-07-12T08:21:26.610306Z",
     "shell.execute_reply": "2025-07-12T08:21:26.609749Z",
     "shell.execute_reply.started": "2025-07-12T08:21:26.481088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KTG samples before cleaning 501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:00<00:00, 4487.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KTG samples after cleaning 501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"KTG samples before cleaning {len(ktg_smiles['SMILES'].notnull())}\")\n",
    "ktg_smiles['SMILES'] = ktg_smiles['SMILES'].progress_apply(lambda s: clean_and_validate_smiles(s))\n",
    "print(f\"KTG samples after cleaning {len(ktg_smiles['SMILES'].notnull())}\")\n",
    "ktg_smiles['Tg'] = ktg_smiles['Tg'] - 273.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T08:21:26.611260Z",
     "iopub.status.busy": "2025-07-12T08:21:26.611007Z",
     "iopub.status.idle": "2025-07-12T08:21:26.862089Z",
     "shell.execute_reply": "2025-07-12T08:21:26.861435Z",
     "shell.execute_reply.started": "2025-07-12T08:21:26.611237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TG samples before cleaning 662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 662/662 [00:00<00:00, 2719.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TG samples after cleaning 662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"TG samples before cleaning {len(tg_smiles['SMILES'].notnull())}\")\n",
    "tg_smiles['SMILES'] = tg_smiles['SMILES'].progress_apply(lambda s: clean_and_validate_smiles(s))\n",
    "print(f\"TG samples after cleaning {len(tg_smiles['SMILES'].notnull())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T08:21:26.863039Z",
     "iopub.status.busy": "2025-07-12T08:21:26.862739Z",
     "iopub.status.idle": "2025-07-12T08:21:27.080087Z",
     "shell.execute_reply": "2025-07-12T08:21:27.079398Z",
     "shell.execute_reply.started": "2025-07-12T08:21:26.863020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TC samples before cleaning 874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 874/874 [00:00<00:00, 4175.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TC samples after cleaning 874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"TC samples before cleaning {len(tc_smiles['SMILES'].notnull())}\")\n",
    "tc_smiles['SMILES'] = tc_smiles['SMILES'].progress_apply(lambda s: clean_and_validate_smiles(s))\n",
    "print(f\"TC samples after cleaning {len(tc_smiles['SMILES'].notnull())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T08:21:27.081552Z",
     "iopub.status.busy": "2025-07-12T08:21:27.080869Z",
     "iopub.status.idle": "2025-07-12T08:21:27.199745Z",
     "shell.execute_reply": "2025-07-12T08:21:27.199076Z",
     "shell.execute_reply.started": "2025-07-12T08:21:27.081534Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DE samples before cleaning 787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 787/787 [00:00<00:00, 7276.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DE samples after cleaning 787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"DE samples before cleaning {len(de_smiles['SMILES'].notnull())}\")\n",
    "de_smiles['SMILES'] = de_smiles['SMILES'].progress_apply(lambda s: clean_and_validate_smiles(s))\n",
    "print(f\"DE samples after cleaning {len(de_smiles['SMILES'].notnull())}\")\n",
    "\n",
    "de_smiles = de_smiles[(de_smiles['SMILES'].notnull())&(de_smiles['Density'].notnull())&(de_smiles['Density'] != 'nylon')]\n",
    "de_smiles['Density'] = de_smiles['Density'].astype('float64')\n",
    "de_smiles['Density'] -= 0.118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T08:21:27.200619Z",
     "iopub.status.busy": "2025-07-12T08:21:27.200446Z",
     "iopub.status.idle": "2025-07-12T08:21:30.497500Z",
     "shell.execute_reply": "2025-07-12T08:21:30.496836Z",
     "shell.execute_reply.started": "2025-07-12T08:21:27.200606Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TGSS samples before cleaning 7284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7284/7284 [00:03<00:00, 2215.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TGSS samples after cleaning 7284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"TGSS samples before cleaning {len(tgss_smiles['SMILES'].notnull())}\")\n",
    "tgss_smiles['SMILES'] = tgss_smiles['SMILES'].progress_apply(lambda s: clean_and_validate_smiles(s))\n",
    "print(f\"TGSS samples after cleaning {len(tgss_smiles['SMILES'].notnull())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T08:21:30.498935Z",
     "iopub.status.busy": "2025-07-12T08:21:30.498264Z",
     "iopub.status.idle": "2025-07-12T08:21:30.504080Z",
     "shell.execute_reply": "2025-07-12T08:21:30.503468Z",
     "shell.execute_reply.started": "2025-07-12T08:21:30.498909Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    desc_names = [desc[0] for desc in Descriptors.descList if desc[0] not in useless_cols]\n",
    "    descriptors = [compute_all_descriptors(smi) for smi in df['SMILES'].to_list()]\n",
    "\n",
    "    graph_feats = {'graph_diameter': [], 'avg_shortest_path': [], 'num_cycles': []}\n",
    "    morgan_feats = {f\"morgan_{i}\" : [] for i in range(1024)}\n",
    "    \n",
    "    for smile in df['SMILES']:\n",
    "        compute_graph_features(smile, graph_feats)\n",
    "        fp_bits = compute_morgan_fingerprint(smile)\n",
    "        for i, bit in enumerate(fp_bits):\n",
    "            morgan_feats[f\"morgan_{i}\"].append(int(bit))\n",
    "\n",
    "    result = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(descriptors, columns=desc_names),\n",
    "            pd.DataFrame(graph_feats),\n",
    "            pd.DataFrame(morgan_feats)\n",
    "        ],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    result = result.replace([-np.inf, np.inf], np.nan)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T08:21:30.504989Z",
     "iopub.status.busy": "2025-07-12T08:21:30.504761Z",
     "iopub.status.idle": "2025-07-12T08:21:39.704521Z",
     "shell.execute_reply": "2025-07-12T08:21:39.703846Z",
     "shell.execute_reply.started": "2025-07-12T08:21:30.504974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For target \"Tc\" added 129 new samples!\n",
      "New unique SMILES: 129\n",
      "\n",
      "For target \"Tg\" added 151 new samples!\n",
      "New unique SMILES: 136\n",
      "\n",
      "For target \"Tg\" added 499 new samples!\n",
      "New unique SMILES: 499\n",
      "\n",
      "For target \"Tg\" added 7083 new samples!\n",
      "New unique SMILES: 1845\n",
      "\n",
      "For target \"Density\" added 634 new samples!\n",
      "New unique SMILES: 473\n"
     ]
    }
   ],
   "source": [
    "def add_extra_data(df_train, df_extra, target):\n",
    "    n_samples_before = len(df_train[df_train[target].notnull()])\n",
    "    \n",
    "    df_extra = df_extra.groupby('SMILES', as_index=False)[target].mean()\n",
    "    cross_smiles = set(df_extra['SMILES']) & set(df_train['SMILES'])\n",
    "    unique_smiles_extra = set(df_extra['SMILES']) - set(df_train['SMILES'])\n",
    "\n",
    "    # Make priority target value from competition's df\n",
    "    for smile in df_train[df_train[target].notnull()]['SMILES'].tolist():\n",
    "        if smile in cross_smiles:\n",
    "            cross_smiles.remove(smile)\n",
    "\n",
    "    # Imput missing values for competition's SMILES\n",
    "    for smile in cross_smiles:\n",
    "        df_train.loc[df_train['SMILES']==smile, target] = df_extra[df_extra['SMILES']==smile][target].values[0]\n",
    "    \n",
    "    df_train = pd.concat([df_train, df_extra[df_extra['SMILES'].isin(unique_smiles_extra)]], axis=0).reset_index(drop=True)\n",
    "\n",
    "    n_samples_after = len(df_train[df_train[target].notnull()])\n",
    "    print(f'\\nFor target \"{target}\" added {n_samples_after-n_samples_before} new samples!')\n",
    "    print(f'New unique SMILES: {len(unique_smiles_extra)}')\n",
    "    return df_train\n",
    "\n",
    "train = add_extra_data(train, tc_smiles, 'Tc')\n",
    "train = add_extra_data(train, tg_smiles, 'Tg')\n",
    "train = add_extra_data(train, ktg_smiles, 'Tg')\n",
    "train = add_extra_data(train, tgss_smiles, 'Tg')\n",
    "train = add_extra_data(train, de_smiles, 'Density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T08:21:39.705676Z",
     "iopub.status.busy": "2025-07-12T08:21:39.705373Z",
     "iopub.status.idle": "2025-07-12T08:21:39.714967Z",
     "shell.execute_reply": "2025-07-12T08:21:39.714225Z",
     "shell.execute_reply.started": "2025-07-12T08:21:39.705653Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_all_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return [None] * len(desc_names)\n",
    "    return [desc[1](mol) for desc in Descriptors.descList if desc[0] not in useless_cols]\n",
    "\n",
    "def compute_graph_features(smiles, graph_feats):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    adj = rdmolops.GetAdjacencyMatrix(mol)\n",
    "    G = nx.from_numpy_array(adj)\n",
    "\n",
    "    graph_feats['graph_diameter'].append(nx.diameter(G) if nx.is_connected(G) else 0)\n",
    "    graph_feats['avg_shortest_path'].append(nx.average_shortest_path_length(G) if nx.is_connected(G) else 0)\n",
    "    graph_feats['num_cycles'].append(len(list(nx.cycle_basis(G))))\n",
    "\n",
    "def compute_morgan_fingerprint(smiles, radius=2, n_bits=1024):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return {f'morgan_{i}': 0 for i in range(n_bits)}\n",
    "\n",
    "    generator = GetMorganGenerator(radius=radius, fpSize=n_bits)\n",
    "    fp = generator.GetFingerprint(mol)\n",
    "    # Convert to bit string\n",
    "    fp_bits = fp.ToBitString()\n",
    "    \n",
    "    return fp_bits\n",
    "\n",
    "def element_features(df):\n",
    "    basic_features = []\n",
    "    for smile in df['SMILES']:\n",
    "        smiles_str = str(smile)\n",
    "        basic_features.append({\n",
    "                'smiles_length': len(smiles_str),\n",
    "                'carbon_count': smiles_str.count('C'),\n",
    "                'nitrogen_count': smiles_str.count('N'),\n",
    "                'oxygen_count': smiles_str.count('O'),\n",
    "                'sulfur_count': smiles_str.count('S'),\n",
    "                'phosphorus_count': smiles_str.count('P'),\n",
    "                'fluorine_count': smiles_str.count('F'),\n",
    "                'chlorine_count': smiles_str.count('Cl'),\n",
    "                'bromine_count': smiles_str.count('Br'),\n",
    "                'iodine_count': smiles_str.count('I'),\n",
    "                'double_bonds': smiles_str.count('='),\n",
    "                'triple_bonds': smiles_str.count('#'),\n",
    "                'rings': smiles_str.count('('),\n",
    "                'aromatic_c': smiles_str.count('c'),\n",
    "                'aromatic_n': smiles_str.count('n'),\n",
    "                'aromatic_o': smiles_str.count('o'),\n",
    "                'branches': smiles_str.count('['),\n",
    "                'polymer_stars': smiles_str.count('*')\n",
    "            })\n",
    "        return pd.DataFrame(basic_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T08:21:39.737672Z",
     "iopub.status.busy": "2025-07-12T08:21:39.737419Z",
     "iopub.status.idle": "2025-07-12T08:24:00.005714Z",
     "shell.execute_reply": "2025-07-12T08:24:00.005128Z",
     "shell.execute_reply.started": "2025-07-12T08:21:39.737656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11055, 1200)\n"
     ]
    }
   ],
   "source": [
    "train = pd.concat([train, preprocessing(train), element_features(train)], axis=1)\n",
    "test = pd.concat([test, preprocessing(test), element_features(train)], axis=1)\n",
    "\n",
    "print(train.shape)\n",
    "train['Ipc']=np.log10(train['Ipc'])  \n",
    "for n in train.columns[7:]:\n",
    "    train[n]=train[n].replace(-np.inf,np.nan)\n",
    "    train[n]=train[n].replace(np.inf,np.nan)    \n",
    "    train[n].fillna(train[n].mean())\n",
    "  \n",
    "test['Ipc']=np.log10(test['Ipc'])\n",
    "for n in test.columns[7:]:\n",
    "    train[n]=train[n].replace(-np.inf,np.nan)\n",
    "    train[n]=train[n].replace(np.inf,np.nan)      \n",
    "    test[n].fillna(train[n].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T08:21:39.716123Z",
     "iopub.status.busy": "2025-07-12T08:21:39.715767Z",
     "iopub.status.idle": "2025-07-12T08:21:39.736642Z",
     "shell.execute_reply": "2025-07-12T08:21:39.735932Z",
     "shell.execute_reply.started": "2025-07-12T08:21:39.716071Z"
    }
   },
   "outputs": [],
   "source": [
    "all_features = train.columns.tolist()[7:]\n",
    "features_by_target = {}\n",
    "\n",
    "for target in CFG.TARGETS:\n",
    "    target_data = train[train[target].notnull()]\n",
    "    if len(target_data) == 0:\n",
    "        print(f\"No data for {target}, skipping\")\n",
    "        features_by_target[target] = []\n",
    "        continue\n",
    "\n",
    "    good_features = []\n",
    "    for col in all_features:\n",
    "        if col in target_data.columns:\n",
    "            values = target_data[col]\n",
    "\n",
    "            if values.nunique() <= 1: continue\n",
    "            if (values == 0).mean() > 0.98: continue\n",
    "            if values.isnull().mean() > 0.5: continue\n",
    "\n",
    "            good_features.append(col)\n",
    "    features_by_target[target] = good_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T08:24:00.008704Z",
     "iopub.status.busy": "2025-07-12T08:24:00.008508Z",
     "iopub.status.idle": "2025-07-12T08:24:00.016151Z",
     "shell.execute_reply": "2025-07-12T08:24:00.015429Z",
     "shell.execute_reply.started": "2025-07-12T08:24:00.008690Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial, X, y, groups, feature_names):\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'mae',\n",
    "        'seed': CFG.SEED,\n",
    "        'verbosity': 0,\n",
    "        'tree_method': 'hist',\n",
    "        'missing': 0.0,\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),  # Reduced max depth\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 1.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True),\n",
    "        'gamma': trial.suggest_float('gamma', 1e-8, 1.0, log=True),\n",
    "    }\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        params['tree_method'] = 'gpu_hist'\n",
    "        params['gpu_id'] = 0\n",
    "\n",
    "    group_kfold = GroupKFold(n_splits=CFG.FOLDS)\n",
    "    cv_scores = []\n",
    "\n",
    "    for train_idx, valid_idx in group_kfold.split(X, y, groups=groups):\n",
    "        X_train, X_valid = X[train_idx], X[valid_idx]\n",
    "        y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "\n",
    "    # Additional cleaning for each fold\n",
    "    X_train = np.nan_to_num(X_train, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    X_valid = np.nan_to_num(X_valid, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train, missing=0.0)\n",
    "    dvalid = xgb.DMatrix(X_valid, label=y_valid, missing=0.0)\n",
    "    \n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=CFG.MAX_ITERATIONS,\n",
    "        evals=[(dtrain, 'train'), (dvalid, 'valid')],\n",
    "        early_stopping_rounds=CFG.EARLY_STOPPING,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "\n",
    "    cv_scores.append(model.best_score)\n",
    "        \n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T08:24:00.017321Z",
     "iopub.status.busy": "2025-07-12T08:24:00.017039Z",
     "iopub.status.idle": "2025-07-12T08:24:00.036900Z",
     "shell.execute_reply": "2025-07-12T08:24:00.036289Z",
     "shell.execute_reply.started": "2025-07-12T08:24:00.017296Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_optimized_model(target):\n",
    "    print(f\"training model for {target}\")\n",
    "    target_data = train[train[target].notnull()].reset_index(drop=True)\n",
    "    if len(target_data) < 50:\n",
    "        print(f\"Not enough data for {target}\")\n",
    "        return None, None\n",
    "\n",
    "    target_features = features_by_target[target]\n",
    "    if len(target_features) == 0:\n",
    "        print(f\"No features available for {target}\")\n",
    "        return None, None\n",
    "\n",
    "    X = target_data[target_features].values\n",
    "    y = target_data[target].values\n",
    "    groups = target_data['SMILES'].factorize()[0]\n",
    "\n",
    "    print(f\"Initial data: {len(target_data)} samples, {X.shape[1]} features\")\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        direction='minimize',\n",
    "        sampler=optuna.samplers.TPESampler(seed=CFG.SEED),\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=5)  # More aggressive pruning\n",
    "    )\n",
    "\n",
    "    study.optimize(\n",
    "            lambda trial: objective(trial, X, y, groups, target_features),\n",
    "            n_trials=CFG.N_TRIALS,\n",
    "            show_progress_bar=True,\n",
    "            timeout=1800  # 30 minute timeout per target\n",
    "        )\n",
    "\n",
    "    best_params = {\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'mae', \n",
    "            'seed': CFG.SEED,\n",
    "            'verbosity': 0,\n",
    "            'tree_method': 'gpu_hist' if torch.cuda.is_available() else 'hist',\n",
    "            'missing': 0.0\n",
    "        }\n",
    "    best_params.update(study.best_params)\n",
    "    \n",
    "    print(f\"Best CV MAE: {study.best_value:.5f}\")\n",
    "\n",
    "    X_final = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    dtrain = xgb.DMatrix(X_final, label=y, missing=0.0)\n",
    "        \n",
    "    final_model = xgb.train(\n",
    "        best_params,\n",
    "        dtrain,\n",
    "        num_boost_round=CFG.MAX_ITERATIONS,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "\n",
    "    train_pred = final_model.predict(dtrain)\n",
    "    train_mae = mean_absolute_error(y, train_pred)\n",
    "    \n",
    "    print(f\"{target} complete - CV: {study.best_value:.5f}, Train: {train_mae:.5f}\")\n",
    "    \n",
    "    return final_model, {\n",
    "        'cv_mae': study.best_value,\n",
    "        'train_mae': train_mae,\n",
    "        'best_params': best_params,\n",
    "        'n_samples': len(target_data),\n",
    "        'features': clean_features  # Store the cleaned feature names\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T08:24:00.037705Z",
     "iopub.status.busy": "2025-07-12T08:24:00.037520Z",
     "iopub.status.idle": "2025-07-12T08:24:00.677023Z",
     "shell.execute_reply": "2025-07-12T08:24:00.676335Z",
     "shell.execute_reply.started": "2025-07-12T08:24:00.037690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training optimized models\n",
      "training model for Tg\n",
      "No features available for Tg\n",
      "training model for FFV\n",
      "No features available for FFV\n",
      "training model for Tc\n",
      "No features available for Tc\n",
      "training model for Density\n",
      "No features available for Density\n",
      "training model for Rg\n",
      "No features available for Rg\n",
      "\n",
      "Training complete!\n",
      "Successfully trained models: []\n",
      "\n",
      "Results Summary:\n"
     ]
    }
   ],
   "source": [
    "print(\"Training optimized models\")\n",
    "models = {}\n",
    "results = {}\n",
    "\n",
    "for target in CFG.TARGETS:\n",
    "    model, result = train_optimized_model(target)\n",
    "    if model is not None:\n",
    "        models[target] = model\n",
    "        results[target] = result\n",
    "\n",
    "print(f\"\\nTraining complete!\")\n",
    "print(f\"Successfully trained models: {list(models.keys())}\")\n",
    "\n",
    "print(f\"\\nResults Summary:\")\n",
    "for target, result in results.items():\n",
    "    print(f\"{target}: CV={result['cv_mae']:.5f}, Train={result['train_mae']:.5f}, Samples={result['n_samples']:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12966160,
     "isSourceIdPinned": false,
     "sourceId": 74608,
     "sourceType": "competition"
    },
    {
     "datasetId": 7678100,
     "sourceId": 12189904,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7690162,
     "sourceId": 12207625,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7709869,
     "sourceId": 12330396,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7709500,
     "sourceId": 12235747,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
