{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":74608,"databundleVersionId":12966160,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":12189904,"sourceType":"datasetVersion","datasetId":7678100},{"sourceId":12207625,"sourceType":"datasetVersion","datasetId":7690162},{"sourceId":12235747,"sourceType":"datasetVersion","datasetId":7709500},{"sourceId":12330396,"sourceType":"datasetVersion","datasetId":7709869}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install /kaggle/input/rdkit-2025-3-3-cp311/rdkit-2025.3.3-cp311-cp311-manylinux_2_28_x86_64.whl","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:22:43.049335Z","iopub.execute_input":"2025-07-17T06:22:43.049605Z","iopub.status.idle":"2025-07-17T06:22:48.667646Z","shell.execute_reply.started":"2025-07-17T06:22:43.049579Z","shell.execute_reply":"2025-07-17T06:22:48.666793Z"}},"outputs":[{"name":"stdout","text":"Processing /kaggle/input/rdkit-2025-3-3-cp311/rdkit-2025.3.3-cp311-cp311-manylinux_2_28_x86_64.whl\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit==2025.3.3) (1.26.4)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit==2025.3.3) (11.2.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rdkit==2025.3.3) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rdkit==2025.3.3) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rdkit==2025.3.3) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rdkit==2025.3.3) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rdkit==2025.3.3) (2024.2.0)\nInstalling collected packages: rdkit\nSuccessfully installed rdkit-2025.3.3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom tqdm import tqdm\ntqdm.pandas()\n\nfrom sklearn.ensemble import HistGradientBoostingRegressor,ExtraTreesRegressor\nfrom catboost import CatBoostRegressor\nfrom sklearn.model_selection import train_test_split, GroupKFold\nfrom sklearn.metrics import mean_absolute_error\n\n\nimport networkx as nx\nfrom rdkit.Chem import AllChem\nfrom rdkit.Chem import Descriptors\nfrom rdkit.Chem import rdmolops\nfrom rdkit import Chem\nfrom rdkit.Chem.rdFingerprintGenerator import GetMorganGenerator\n\nimport xgboost as xgb\nimport torch\nimport optuna\noptuna.logging.set_verbosity(optuna.logging.WARNING)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_columns', None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:22:48.669298Z","iopub.execute_input":"2025-07-17T06:22:48.669572Z","iopub.status.idle":"2025-07-17T06:22:55.145093Z","shell.execute_reply.started":"2025-07-17T06:22:48.669542Z","shell.execute_reply":"2025-07-17T06:22:55.144332Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class CFG:\n    TARGETS = ['Tg', 'FFV', 'Tc', 'Density', 'Rg']\n    SEED = 42\n    FOLDS = 5\n\n    # Optimization settings\n    N_TRIALS = 10  # Optuna trials per target\n    EARLY_STOPPING = 100\n    MAX_ITERATIONS = 5000\n    \n    # Model settings\n    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:22:55.145952Z","iopub.execute_input":"2025-07-17T06:22:55.146473Z","iopub.status.idle":"2025-07-17T06:22:55.215272Z","shell.execute_reply.started":"2025-07-17T06:22:55.146443Z","shell.execute_reply":"2025-07-17T06:22:55.214534Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"useless_cols = [   \n    \n    'MaxPartialCharge', \n    # Nan data\n    'BCUT2D_MWHI',\n    'BCUT2D_MWLOW',\n    'BCUT2D_CHGHI',\n    'BCUT2D_CHGLO',\n    'BCUT2D_LOGPHI',\n    'BCUT2D_LOGPLOW',\n    'BCUT2D_MRHI',\n    'BCUT2D_MRLOW',\n\n    # Constant data\n    'NumRadicalElectrons',\n    'SMR_VSA8',\n    'SlogP_VSA9',\n    'fr_barbitur',\n    'fr_benzodiazepine',\n    'fr_dihydropyridine',\n    'fr_epoxide',\n    'fr_isothiocyan',\n    'fr_lactam',\n    'fr_nitroso',\n    'fr_prisulfonamd',\n    'fr_thiocyan',\n\n    # High correlated data >0.95\n    'MaxEStateIndex',\n    'HeavyAtomMolWt',\n    'ExactMolWt',\n    'NumValenceElectrons',\n    'Chi0',\n    'Chi0n',\n    'Chi0v',\n    'Chi1',\n    'Chi1n',\n    'Chi1v',\n    'Chi2n',\n    'Kappa1',\n    'LabuteASA',\n    'HeavyAtomCount',\n    'MolMR',\n    'Chi3n',\n    'BertzCT',\n    'Chi2v',\n    'Chi4n',\n    'HallKierAlpha',\n    'Chi3v',\n    'Chi4v',\n    'MinAbsPartialCharge',\n    'MinPartialCharge',\n    'MaxAbsPartialCharge',\n    'FpDensityMorgan2',\n    'FpDensityMorgan3',\n    'Phi',\n    'Kappa3',\n    'fr_nitrile',\n    'SlogP_VSA6',\n    'NumAromaticCarbocycles',\n    'NumAromaticRings',\n    'fr_benzene',\n    'VSA_EState6',\n    'NOCount',\n    'fr_C_O',\n    'fr_C_O_noCOO',\n    'NumHDonors',\n    'fr_amide',\n    'fr_Nhpyrrole',\n    'fr_phenol',\n    'fr_phenol_noOrthoHbond',\n    'fr_COO2',\n    'fr_halogen',\n    'fr_diazo',\n    'fr_nitro_arom',\n    'fr_phos_ester'\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:22:55.217234Z","iopub.execute_input":"2025-07-17T06:22:55.218030Z","iopub.status.idle":"2025-07-17T06:22:55.647681Z","shell.execute_reply.started":"2025-07-17T06:22:55.218001Z","shell.execute_reply":"2025-07-17T06:22:55.646832Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"MINMAX_DICT = {\n    'Tg': [-148.0297376, 472.25],\n    'FFV': [0.2269924, 0.77709707], \n    'Tc': [0.0465, 0.524],\n    'Density': [0.748691234, 1.840998909],\n    'Rg': [9.7283551, 34.672905605],\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:22:55.648731Z","iopub.execute_input":"2025-07-17T06:22:55.648988Z","iopub.status.idle":"2025-07-17T06:22:55.668176Z","shell.execute_reply.started":"2025-07-17T06:22:55.648965Z","shell.execute_reply":"2025-07-17T06:22:55.667536Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### Read Main Files","metadata":{}},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/neurips-open-polymer-prediction-2025/train.csv')\ntest=pd.read_csv('/kaggle/input/neurips-open-polymer-prediction-2025/test.csv')\nss=pd.read_csv('/kaggle/input/neurips-open-polymer-prediction-2025/sample_submission.csv')\nID=test['id'].copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:22:55.668865Z","iopub.execute_input":"2025-07-17T06:22:55.669105Z","iopub.status.idle":"2025-07-17T06:22:55.730614Z","shell.execute_reply.started":"2025-07-17T06:22:55.669080Z","shell.execute_reply":"2025-07-17T06:22:55.729945Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### Read Extra Files","metadata":{}},{"cell_type":"code","source":"tc_smiles = pd.read_csv('/kaggle/input/tc-smiles/Tc_SMILES.csv')\ntgss_smiles = pd.read_csv('/kaggle/input/tg-smiles-pid-polymer-class/TgSS_enriched_cleaned.csv')\ntg_smiles =pd.read_csv('/kaggle/input/smiles-extra-data/JCIM_sup_bigsmiles.csv')\nktg_smiles =pd.read_excel('/kaggle/input/smiles-extra-data/data_tg3.xlsx')\nde_smiles =pd.read_excel('/kaggle/input/smiles-extra-data/data_dnst1.xlsx')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:22:55.731243Z","iopub.execute_input":"2025-07-17T06:22:55.731426Z","iopub.status.idle":"2025-07-17T06:22:56.355356Z","shell.execute_reply.started":"2025-07-17T06:22:55.731411Z","shell.execute_reply":"2025-07-17T06:22:56.354294Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### Preprocessing","metadata":{"execution":{"iopub.status.busy":"2025-07-12T05:31:53.317109Z","iopub.execute_input":"2025-07-12T05:31:53.317447Z","iopub.status.idle":"2025-07-12T05:31:53.321755Z","shell.execute_reply.started":"2025-07-12T05:31:53.317424Z","shell.execute_reply":"2025-07-12T05:31:53.320780Z"}}},{"cell_type":"code","source":"def clean_and_validate_smiles(smiles):\n    if not isinstance(smiles, str) or len(smiles) == 0:\n        return None\n\n    bad_patterns = [\n        '[R]', '[R1]', '[R2]', '[R3]', '[R4]', '[R5]', \n        \"[R']\", '[R\"]', 'R1', 'R2', 'R3', 'R4', 'R5',\n        # Additional patterns that cause issues\n        '([R])', '([R1])', '([R2])', \n    ]\n\n    for pattern in bad_patterns:\n        if pattern in smiles:\n            return None\n\n    if '][' in smiles and any(x in smiles for x in ['[R', 'R]']):\n        return None\n\n    mol = Chem.MolFromSmiles(smiles)\n    \n    if mol is not None:\n        return Chem.MolToSmiles(mol, canonical=True)\n    else:\n        return None","metadata":{"execution":{"iopub.status.busy":"2025-07-17T06:22:56.356402Z","iopub.execute_input":"2025-07-17T06:22:56.356809Z","iopub.status.idle":"2025-07-17T06:22:56.362074Z","shell.execute_reply.started":"2025-07-17T06:22:56.356788Z","shell.execute_reply":"2025-07-17T06:22:56.361296Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"print(f\"Train samples before cleaning {len(train['SMILES'].notnull())}\")\nprint(f\"Test samples before cleaning {len(test['SMILES'].notnull())}\")\ntrain['SMILES'] = train['SMILES'].progress_apply(lambda s: clean_and_validate_smiles(s))\ntest['SMILES'] = test['SMILES'].progress_apply(lambda s: clean_and_validate_smiles(s))\nprint(f\"Train samples after cleaning {len(train['SMILES'].notnull())}\")\nprint(f\"Test samples after cleaning {len(test['SMILES'].notnull())}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:22:56.362826Z","iopub.execute_input":"2025-07-17T06:22:56.363043Z","iopub.status.idle":"2025-07-17T06:22:59.895659Z","shell.execute_reply.started":"2025-07-17T06:22:56.363027Z","shell.execute_reply":"2025-07-17T06:22:59.894968Z"}},"outputs":[{"name":"stdout","text":"Train samples before cleaning 7973\nTest samples before cleaning 3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7973/7973 [00:03<00:00, 2277.23it/s]\n100%|██████████| 3/3 [00:00<00:00, 1509.65it/s]","output_type":"stream"},{"name":"stdout","text":"Train samples after cleaning 7973\nTest samples after cleaning 3\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# we don't need to make changes to the tgss df\n\nktg_smiles.rename(columns={'Tg [K]': 'Tg'}, inplace=True)\ntg_smiles.rename(columns={'Tg (C)': 'Tg'}, inplace=True)\ntc_smiles.rename(columns={'TC_mean': 'Tc'}, inplace=True)\nde_smiles.rename(columns={'density(g/cm3)': 'Density'}, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:22:59.898213Z","iopub.execute_input":"2025-07-17T06:22:59.898814Z","iopub.status.idle":"2025-07-17T06:22:59.903634Z","shell.execute_reply.started":"2025-07-17T06:22:59.898796Z","shell.execute_reply":"2025-07-17T06:22:59.902839Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"print(f\"KTG samples before cleaning {len(ktg_smiles['SMILES'].notnull())}\")\nktg_smiles['SMILES'] = ktg_smiles['SMILES'].progress_apply(lambda s: clean_and_validate_smiles(s))\nprint(f\"KTG samples after cleaning {len(ktg_smiles['SMILES'].notnull())}\")\nktg_smiles['Tg'] = ktg_smiles['Tg'] - 273.15","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:22:59.904530Z","iopub.execute_input":"2025-07-17T06:22:59.904798Z","iopub.status.idle":"2025-07-17T06:23:00.064535Z","shell.execute_reply.started":"2025-07-17T06:22:59.904773Z","shell.execute_reply":"2025-07-17T06:23:00.063982Z"}},"outputs":[{"name":"stdout","text":"KTG samples before cleaning 501\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 501/501 [00:00<00:00, 4350.08it/s]","output_type":"stream"},{"name":"stdout","text":"KTG samples after cleaning 501\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"print(f\"TG samples before cleaning {len(tg_smiles['SMILES'].notnull())}\")\ntg_smiles['SMILES'] = tg_smiles['SMILES'].progress_apply(lambda s: clean_and_validate_smiles(s))\nprint(f\"TG samples after cleaning {len(tg_smiles['SMILES'].notnull())}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:23:00.065308Z","iopub.execute_input":"2025-07-17T06:23:00.065518Z","iopub.status.idle":"2025-07-17T06:23:00.317509Z","shell.execute_reply.started":"2025-07-17T06:23:00.065477Z","shell.execute_reply":"2025-07-17T06:23:00.316846Z"}},"outputs":[{"name":"stdout","text":"TG samples before cleaning 662\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 662/662 [00:00<00:00, 2706.36it/s]","output_type":"stream"},{"name":"stdout","text":"TG samples after cleaning 662\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"print(f\"TC samples before cleaning {len(tc_smiles['SMILES'].notnull())}\")\ntc_smiles['SMILES'] = tc_smiles['SMILES'].progress_apply(lambda s: clean_and_validate_smiles(s))\nprint(f\"TC samples after cleaning {len(tc_smiles['SMILES'].notnull())}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:23:00.318194Z","iopub.execute_input":"2025-07-17T06:23:00.318455Z","iopub.status.idle":"2025-07-17T06:23:00.528277Z","shell.execute_reply.started":"2025-07-17T06:23:00.318431Z","shell.execute_reply":"2025-07-17T06:23:00.527515Z"}},"outputs":[{"name":"stdout","text":"TC samples before cleaning 874\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 874/874 [00:00<00:00, 4312.22it/s]","output_type":"stream"},{"name":"stdout","text":"TC samples after cleaning 874\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"print(f\"DE samples before cleaning {len(de_smiles['SMILES'].notnull())}\")\nde_smiles['SMILES'] = de_smiles['SMILES'].progress_apply(lambda s: clean_and_validate_smiles(s))\nprint(f\"DE samples after cleaning {len(de_smiles['SMILES'].notnull())}\")\n\nde_smiles = de_smiles[(de_smiles['SMILES'].notnull())&(de_smiles['Density'].notnull())&(de_smiles['Density'] != 'nylon')]\nde_smiles['Density'] = de_smiles['Density'].astype('float64')\nde_smiles['Density'] -= 0.118","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:23:00.528937Z","iopub.execute_input":"2025-07-17T06:23:00.529161Z","iopub.status.idle":"2025-07-17T06:23:00.653060Z","shell.execute_reply.started":"2025-07-17T06:23:00.529141Z","shell.execute_reply":"2025-07-17T06:23:00.652301Z"}},"outputs":[{"name":"stdout","text":"DE samples before cleaning 787\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 787/787 [00:00<00:00, 7239.81it/s]","output_type":"stream"},{"name":"stdout","text":"DE samples after cleaning 787\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"print(f\"TGSS samples before cleaning {len(tgss_smiles['SMILES'].notnull())}\")\ntgss_smiles['SMILES'] = tgss_smiles['SMILES'].progress_apply(lambda s: clean_and_validate_smiles(s))\nprint(f\"TGSS samples after cleaning {len(tgss_smiles['SMILES'].notnull())}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:23:00.653839Z","iopub.execute_input":"2025-07-17T06:23:00.654070Z","iopub.status.idle":"2025-07-17T06:23:04.011764Z","shell.execute_reply.started":"2025-07-17T06:23:00.654054Z","shell.execute_reply":"2025-07-17T06:23:04.011032Z"}},"outputs":[{"name":"stdout","text":"TGSS samples before cleaning 7284\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7284/7284 [00:03<00:00, 2174.93it/s]","output_type":"stream"},{"name":"stdout","text":"TGSS samples after cleaning 7284\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"def preprocessing(df):\n    desc_names = [desc[0] for desc in Descriptors.descList if desc[0] not in useless_cols]\n    descriptors = [compute_all_descriptors(smi) for smi in df['SMILES'].to_list()]\n\n    graph_feats = {'graph_diameter': [], 'avg_shortest_path': [], 'num_cycles': []}\n    morgan_feats = {f\"morgan_{i}\" : [] for i in range(1024)}\n    \n    for smile in df['SMILES']:\n        compute_graph_features(smile, graph_feats)\n        fp_bits = compute_morgan_fingerprint(smile)\n        for i, bit in enumerate(fp_bits):\n            morgan_feats[f\"morgan_{i}\"].append(int(bit))\n\n    result = pd.concat(\n        [\n            pd.DataFrame(descriptors, columns=desc_names),\n            pd.DataFrame(graph_feats),\n            pd.DataFrame(morgan_feats)\n        ],\n        axis=1\n    )\n\n    result = result.replace([-np.inf, np.inf], np.nan)\n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:23:04.012588Z","iopub.execute_input":"2025-07-17T06:23:04.012824Z","iopub.status.idle":"2025-07-17T06:23:04.018467Z","shell.execute_reply.started":"2025-07-17T06:23:04.012807Z","shell.execute_reply":"2025-07-17T06:23:04.017806Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def add_extra_data(df_train, df_extra, target):\n    n_samples_before = len(df_train[df_train[target].notnull()])\n    \n    df_extra = df_extra.groupby('SMILES', as_index=False)[target].mean()\n    cross_smiles = set(df_extra['SMILES']) & set(df_train['SMILES'])\n    unique_smiles_extra = set(df_extra['SMILES']) - set(df_train['SMILES'])\n\n    # Make priority target value from competition's df\n    for smile in df_train[df_train[target].notnull()]['SMILES'].tolist():\n        if smile in cross_smiles:\n            cross_smiles.remove(smile)\n\n    # Imput missing values for competition's SMILES\n    for smile in cross_smiles:\n        df_train.loc[df_train['SMILES']==smile, target] = df_extra[df_extra['SMILES']==smile][target].values[0]\n    \n    df_train = pd.concat([df_train, df_extra[df_extra['SMILES'].isin(unique_smiles_extra)]], axis=0).reset_index(drop=True)\n\n    n_samples_after = len(df_train[df_train[target].notnull()])\n    print(f'\\nFor target \"{target}\" added {n_samples_after-n_samples_before} new samples!')\n    print(f'New unique SMILES: {len(unique_smiles_extra)}')\n    return df_train\n\ntrain = add_extra_data(train, tc_smiles, 'Tc')\ntrain = add_extra_data(train, tg_smiles, 'Tg')\ntrain = add_extra_data(train, ktg_smiles, 'Tg')\ntrain = add_extra_data(train, tgss_smiles, 'Tg')\ntrain = add_extra_data(train, de_smiles, 'Density')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:23:04.019243Z","iopub.execute_input":"2025-07-17T06:23:04.019467Z","iopub.status.idle":"2025-07-17T06:23:13.186848Z","shell.execute_reply.started":"2025-07-17T06:23:04.019442Z","shell.execute_reply":"2025-07-17T06:23:13.186288Z"}},"outputs":[{"name":"stdout","text":"\nFor target \"Tc\" added 129 new samples!\nNew unique SMILES: 129\n\nFor target \"Tg\" added 151 new samples!\nNew unique SMILES: 136\n\nFor target \"Tg\" added 499 new samples!\nNew unique SMILES: 499\n\nFor target \"Tg\" added 7083 new samples!\nNew unique SMILES: 1845\n\nFor target \"Density\" added 634 new samples!\nNew unique SMILES: 473\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"def compute_all_descriptors(smiles):\n    mol = Chem.MolFromSmiles(smiles)\n    if mol is None:\n        return [None] * len(desc_names)\n    return [desc[1](mol) for desc in Descriptors.descList if desc[0] not in useless_cols]\n\ndef compute_graph_features(smiles, graph_feats):\n    mol = Chem.MolFromSmiles(smiles)\n    adj = rdmolops.GetAdjacencyMatrix(mol)\n    G = nx.from_numpy_array(adj)\n\n    graph_feats['graph_diameter'].append(nx.diameter(G) if nx.is_connected(G) else 0)\n    graph_feats['avg_shortest_path'].append(nx.average_shortest_path_length(G) if nx.is_connected(G) else 0)\n    graph_feats['num_cycles'].append(len(list(nx.cycle_basis(G))))\n\ndef compute_morgan_fingerprint(smiles, radius=2, n_bits=1024):\n    mol = Chem.MolFromSmiles(smiles)\n    if mol is None:\n        return {f'morgan_{i}': 0 for i in range(n_bits)}\n\n    generator = GetMorganGenerator(radius=radius, fpSize=n_bits)\n    fp = generator.GetFingerprint(mol)\n    # Convert to bit string\n    fp_bits = fp.ToBitString()\n    \n    return fp_bits\n\ndef element_features(df):\n    basic_features = []\n    for smile in df['SMILES']:\n        smiles_str = str(smile)\n        basic_features.append({\n                'smiles_length': len(smiles_str),\n                'carbon_count': smiles_str.count('C'),\n                'nitrogen_count': smiles_str.count('N'),\n                'oxygen_count': smiles_str.count('O'),\n                'sulfur_count': smiles_str.count('S'),\n                'phosphorus_count': smiles_str.count('P'),\n                'fluorine_count': smiles_str.count('F'),\n                'chlorine_count': smiles_str.count('Cl'),\n                'bromine_count': smiles_str.count('Br'),\n                'iodine_count': smiles_str.count('I'),\n                'double_bonds': smiles_str.count('='),\n                'triple_bonds': smiles_str.count('#'),\n                'rings': smiles_str.count('('),\n                'aromatic_c': smiles_str.count('c'),\n                'aromatic_n': smiles_str.count('n'),\n                'aromatic_o': smiles_str.count('o'),\n                'branches': smiles_str.count('['),\n                'polymer_stars': smiles_str.count('*')\n            })\n        return pd.DataFrame(basic_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:23:13.187667Z","iopub.execute_input":"2025-07-17T06:23:13.187977Z","iopub.status.idle":"2025-07-17T06:23:13.196163Z","shell.execute_reply.started":"2025-07-17T06:23:13.187957Z","shell.execute_reply":"2025-07-17T06:23:13.195482Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"train = pd.concat([train, preprocessing(train), element_features(train)], axis=1)\ntest = pd.concat([test, preprocessing(test), element_features(train)], axis=1)\n\nprint(train.shape)\ntrain['Ipc']=np.log10(train['Ipc'])  \nfor n in train.columns[7:]:\n    train[n]=train[n].replace(-np.inf,np.nan)\n    train[n]=train[n].replace(np.inf,np.nan)    \n    train[n].fillna(train[n].mean())\n  \ntest['Ipc']=np.log10(test['Ipc'])\nfor n in test.columns[7:]:\n    test[n]=test[n].replace(-np.inf,np.nan)\n    test[n]=test[n].replace(np.inf,np.nan)      \n    test[n].fillna(train[n].mean())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:23:13.196912Z","iopub.execute_input":"2025-07-17T06:23:13.197114Z","iopub.status.idle":"2025-07-17T06:25:35.213825Z","shell.execute_reply.started":"2025-07-17T06:23:13.197099Z","shell.execute_reply":"2025-07-17T06:25:35.213086Z"}},"outputs":[{"name":"stdout","text":"(11055, 1200)\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"all_features = train.columns.tolist()[7:]\nfeatures_by_target = {}\n\nfor target in CFG.TARGETS:\n    target_data = train[train[target].notnull()]\n    if len(target_data) == 0:\n        print(f\"No data for {target}, skipping\")\n        features_by_target[target] = []\n        continue\n\n    good_features = []\n    for col in all_features:\n        if col in target_data.columns:\n            values = target_data[col]\n\n            if values.nunique() <= 1: continue\n            if (values == 0).mean() > 0.98: continue\n            if values.isnull().mean() > 0.5: continue\n\n            good_features.append(col)\n    features_by_target[target] = good_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:25:35.214583Z","iopub.execute_input":"2025-07-17T06:25:35.214840Z","iopub.status.idle":"2025-07-17T06:25:36.826632Z","shell.execute_reply.started":"2025-07-17T06:25:35.214815Z","shell.execute_reply":"2025-07-17T06:25:36.826034Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"#len(features_by_target['Tg'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:25:36.827299Z","iopub.execute_input":"2025-07-17T06:25:36.827545Z","iopub.status.idle":"2025-07-17T06:25:36.831042Z","shell.execute_reply.started":"2025-07-17T06:25:36.827521Z","shell.execute_reply":"2025-07-17T06:25:36.830266Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def objective(trial, X, y, groups, feature_names):\n    params = {\n        'objective': 'reg:squarederror',\n        'eval_metric': 'mae',\n        'seed': CFG.SEED,\n        'verbosity': 0,\n        'tree_method': 'hist',\n        'missing': 0.0,\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n        'max_depth': trial.suggest_int('max_depth', 3, 12),  # Reduced max depth\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 1.0, log=True),\n        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True),\n        'gamma': trial.suggest_float('gamma', 1e-8, 1.0, log=True),\n    }\n\n    if torch.cuda.is_available():\n        params['tree_method'] = 'gpu_hist'\n        params['gpu_id'] = 0\n\n    group_kfold = GroupKFold(n_splits=CFG.FOLDS)\n    cv_scores = []\n\n    for train_idx, valid_idx in group_kfold.split(X, y, groups=groups):\n        X_train, X_valid = X[train_idx], X[valid_idx]\n        y_train, y_valid = y[train_idx], y[valid_idx]\n\n        # Additional cleaning for each fold\n        X_train = np.nan_to_num(X_train, nan=0.0, posinf=0.0, neginf=0.0)\n        X_valid = np.nan_to_num(X_valid, nan=0.0, posinf=0.0, neginf=0.0)\n        \n        dtrain = xgb.DMatrix(X_train, label=y_train, missing=0.0)\n        dvalid = xgb.DMatrix(X_valid, label=y_valid, missing=0.0)\n        \n        model = xgb.train(\n            params,\n            dtrain,\n            num_boost_round=CFG.MAX_ITERATIONS,\n            evals=[(dtrain, 'train'), (dvalid, 'valid')],\n            early_stopping_rounds=CFG.EARLY_STOPPING,\n            verbose_eval=False\n        )\n\n        cv_scores.append(model.best_score)\n        \n    return np.mean(cv_scores)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:25:36.831762Z","iopub.execute_input":"2025-07-17T06:25:36.831959Z","iopub.status.idle":"2025-07-17T06:25:36.847358Z","shell.execute_reply.started":"2025-07-17T06:25:36.831942Z","shell.execute_reply":"2025-07-17T06:25:36.846771Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def train_optimized_model(target):\n    print(f\"training model for {target}\")\n    target_data = train[train[target].notnull()].reset_index(drop=True)\n    if len(target_data) < 50:\n        print(f\"Not enough data for {target}\")\n        return None, None\n\n    target_features = features_by_target[target]\n    if len(target_features) == 0:\n        print(f\"No features available for {target}\")\n        return None, None\n\n    X = target_data[target_features].values\n    y = target_data[target].values\n    groups = target_data['SMILES'].factorize()[0]\n\n    print(f\"Initial data: {len(target_data)} samples, {X.shape[1]} features\")\n\n    study = optuna.create_study(\n        direction='minimize',\n        sampler=optuna.samplers.TPESampler(seed=CFG.SEED),\n        pruner=optuna.pruners.MedianPruner(n_warmup_steps=5)  # More aggressive pruning\n    )\n\n    study.optimize(\n            lambda trial: objective(trial, X, y, groups, target_features),\n            n_trials=CFG.N_TRIALS,\n            show_progress_bar=True,\n            timeout=1800  # 30 minute timeout per target\n        )\n\n    best_params = {\n            'objective': 'reg:squarederror',\n            'eval_metric': 'mae', \n            'seed': CFG.SEED,\n            'verbosity': 0,\n            'tree_method': 'gpu_hist' if torch.cuda.is_available() else 'hist',\n            'missing': 0.0\n        }\n    best_params.update(study.best_params)\n    \n    print(f\"Best CV MAE: {study.best_value:.5f}\")\n\n    X_final = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n    dtrain = xgb.DMatrix(X_final, label=y, missing=0.0)\n        \n    final_model = xgb.train(\n        best_params,\n        dtrain,\n        num_boost_round=CFG.MAX_ITERATIONS,\n        verbose_eval=False\n    )\n\n    train_pred = final_model.predict(dtrain)\n    train_mae = mean_absolute_error(y, train_pred)\n    \n    print(f\"{target} complete - CV: {study.best_value:.5f}, Train: {train_mae:.5f}\")\n    \n    return final_model, {\n        'cv_mae': study.best_value,\n        'train_mae': train_mae,\n        'best_params': best_params,\n        'n_samples': len(target_data),\n        'features': target_features  # Store the cleaned feature names\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:25:36.848105Z","iopub.execute_input":"2025-07-17T06:25:36.848613Z","iopub.status.idle":"2025-07-17T06:25:36.869128Z","shell.execute_reply.started":"2025-07-17T06:25:36.848596Z","shell.execute_reply":"2025-07-17T06:25:36.868452Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"print(\"Training optimized models\")\nmodels = {}\nresults = {}\n\nfor target in CFG.TARGETS:\n    model, result = train_optimized_model(target)\n    if model is not None:\n        models[target] = model\n        results[target] = result\n\nprint(f\"\\nTraining complete!\")\nprint(f\"Successfully trained models: {list(models.keys())}\")\n\nprint(f\"\\nResults Summary:\")\nfor target, result in results.items():\n    print(f\"{target}: CV={result['cv_mae']:.5f}, Train={result['train_mae']:.5f}, Samples={result['n_samples']:,}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:25:36.869997Z","iopub.execute_input":"2025-07-17T06:25:36.870714Z","iopub.status.idle":"2025-07-17T06:43:30.234784Z","shell.execute_reply.started":"2025-07-17T06:25:36.870689Z","shell.execute_reply":"2025-07-17T06:43:30.233983Z"}},"outputs":[{"name":"stdout","text":"Training optimized models\ntraining model for Tg\nInitial data: 8244 samples, 461 features\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f2d3376d0f942bc97c9b043f5ed8675"}},"metadata":{}},{"name":"stdout","text":"Best CV MAE: 24.70822\nTg complete - CV: 24.70822, Train: 2.08832\ntraining model for FFV\nInitial data: 7030 samples, 464 features\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47aecfbb077c436ea5b08bb2f3b9137a"}},"metadata":{}},{"name":"stdout","text":"Best CV MAE: 0.00590\nFFV complete - CV: 0.00590, Train: 0.00263\ntraining model for Tc\nInitial data: 866 samples, 323 features\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cb6af5af6684622b9e33ef01622732a"}},"metadata":{}},{"name":"stdout","text":"Best CV MAE: 0.03154\nTc complete - CV: 0.03154, Train: 0.00247\ntraining model for Density\nInitial data: 1247 samples, 326 features\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e4068572fe546cbaae6c89bad378648"}},"metadata":{}},{"name":"stdout","text":"Best CV MAE: 0.03687\nDensity complete - CV: 0.03687, Train: 0.00227\ntraining model for Rg\nInitial data: 614 samples, 320 features\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"383f4eabfe584121a7b90dc924f8b8f2"}},"metadata":{}},{"name":"stdout","text":"Best CV MAE: 1.62229\nRg complete - CV: 1.62229, Train: 0.20237\n\nTraining complete!\nSuccessfully trained models: ['Tg', 'FFV', 'Tc', 'Density', 'Rg']\n\nResults Summary:\nTg: CV=24.70822, Train=2.08832, Samples=8,244\nFFV: CV=0.00590, Train=0.00263, Samples=7,030\nTc: CV=0.03154, Train=0.00247, Samples=866\nDensity: CV=0.03687, Train=0.00227, Samples=1,247\nRg: CV=1.62229, Train=0.20237, Samples=614\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"def get_predictions():\n\n    test_predictions = pd.DataFrame({'id': test['id']})\n    for target in CFG.TARGETS:\n        test_predictions[target] = 0.0\n\n    for target in CFG.TARGETS:\n        if target in models and target in results:\n            model_features = results[target]['features']\n            X_test = test[model_features].values\n            dtest = xgb.DMatrix(X_test, missing=0.0)\n            preds = models[target].predict(dtest)\n            print(f\"Predictions generated for {target}\")\n            test_predictions[target] = preds\n\n    return test_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:43:30.235636Z","iopub.execute_input":"2025-07-17T06:43:30.235856Z","iopub.status.idle":"2025-07-17T06:43:30.240694Z","shell.execute_reply.started":"2025-07-17T06:43:30.235839Z","shell.execute_reply":"2025-07-17T06:43:30.240037Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"preds_df = get_predictions()\npreds_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:43:30.241302Z","iopub.execute_input":"2025-07-17T06:43:30.241468Z","iopub.status.idle":"2025-07-17T06:43:31.026019Z","shell.execute_reply.started":"2025-07-17T06:43:30.241455Z","shell.execute_reply":"2025-07-17T06:43:31.025422Z"}},"outputs":[{"name":"stdout","text":"Predictions generated for Tg\nPredictions generated for FFV\nPredictions generated for Tc\nPredictions generated for Density\nPredictions generated for Rg\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"           id          Tg       FFV        Tc   Density         Rg\n0  1109053969  163.403503  0.379260  0.170384  1.118323  25.059658\n1  1422188626  151.448853  0.379027  0.217572  1.089272  20.681328\n2  2032016830  141.366653  0.350825  0.245006  1.097334  20.486364","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Tg</th>\n      <th>FFV</th>\n      <th>Tc</th>\n      <th>Density</th>\n      <th>Rg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1109053969</td>\n      <td>163.403503</td>\n      <td>0.379260</td>\n      <td>0.170384</td>\n      <td>1.118323</td>\n      <td>25.059658</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1422188626</td>\n      <td>151.448853</td>\n      <td>0.379027</td>\n      <td>0.217572</td>\n      <td>1.089272</td>\n      <td>20.681328</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2032016830</td>\n      <td>141.366653</td>\n      <td>0.350825</td>\n      <td>0.245006</td>\n      <td>1.097334</td>\n      <td>20.486364</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"# preds_df.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:43:31.026685Z","iopub.execute_input":"2025-07-17T06:43:31.026938Z","iopub.status.idle":"2025-07-17T06:43:31.030207Z","shell.execute_reply.started":"2025-07-17T06:43:31.026916Z","shell.execute_reply":"2025-07-17T06:43:31.029552Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"print(\"Handling data leakage (overlappint SMILES)\")\n\nleakage_stats = {}\n\nfor target in CFG.TARGETS:\n# Get training data with known values for this target\n    train_sub = train[train[target].notnull()][['SMILES', target]].drop_duplicates()\n\n    if len(train_sub) == 0:\n        leakage_stats[target] = 0\n    #create look up directory {smiles : target values}\n    smiles_to_target = dict(zip(train_sub['SMILES'], train_sub[target]))\n\n    # Find overlapping SMILES in test set\n    test_smiles = test['SMILES'].values\n    overlapping_count = 0\n\n    for idx in range(len(test_smiles)):\n        if test_smiles[idx] in smiles_to_target:\n            preds_df.loc[idx, target] = smiles_to_target[test_smiles[idx]]\n            overlapping_count += 1\n\n    leakage_stats[target] = overlapping_count\n\n    print(f\"replaced {overlapping_count} matches for {target}\")\n\n\nprint(\"\\n final predictions\")\nfinal_predictions = preds_df.copy()\n\n# clip predictions to target range\nfor target in CFG.TARGETS:\n    train_values = train[target].dropna()\n    if len(train_values) > 0:\n        lower_bound = train_values.quantile(0.01)\n        upper_bound = train_values.quantile(0.99)\n\n        before_clip = final_predictions[target].copy()\n        final_predictions[target] = np.clip(\n            final_predictions[target],\n            lower_bound,\n            upper_bound\n        )\n\n    clipped_count = (before_clip != final_predictions[target]).sum()\n\n    if clipped_count > 0:\n        print(f\"for {target}, {clipped_count} values clipped\")\n\n# final validation\nsubmission_final = final_predictions[['id'] + CFG.TARGETS].copy()\n\nfor target in CFG.TARGETS:\n    preds = submission_final[target]\n    nan_counts = preds.isna().sum()\n    inf_counts = np.isinf(preds).sum()\n\n    if nan_counts > 0:\n        print(f'for {target}, {nan_counts} nan values found, replacing with median')\n        median_val = train[target].median()\n        submission_final[target] = preds.fillna(median_val)\n\n    if inf_counts > 0:\n        print(f'for {target}, {inf_counts} nan values found, replacing with median')\n        median_val = train[target].median()\n        submission_final[target] = preds.replace([np.inf, -np.inf], median_val)\n    \n    final_preds = submission_final[target]\n    print(f\"{target}: [{final_preds.min():.3f}, {final_preds.max():.3f}], mean={final_preds.mean():.3f}\")\n\nsubmission_final.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:46:37.300088Z","iopub.execute_input":"2025-07-17T06:46:37.300672Z","iopub.status.idle":"2025-07-17T06:46:37.531159Z","shell.execute_reply.started":"2025-07-17T06:46:37.300646Z","shell.execute_reply":"2025-07-17T06:46:37.530606Z"}},"outputs":[{"name":"stdout","text":"Handling data leakage (overlappint SMILES)\nreplaced 2 matches for Tg\nreplaced 0 matches for FFV\nreplaced 0 matches for Tc\nreplaced 0 matches for Density\nreplaced 0 matches for Rg\n\n final predictions\nTg: [142.000, 163.404], mean=152.801\nFFV: [0.351, 0.379], mean=0.370\nTc: [0.170, 0.245], mean=0.211\nDensity: [1.089, 1.118], mean=1.102\nRg: [20.486, 25.060], mean=22.076\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# Show leakage summary\ntotal_leakage = sum(leakage_stats.values())\nif total_leakage > 0:\n    print(f\"\\n Data leakage handled:\")\n    print(f\"Total exact matches: {total_leakage}\")\n    for target, count in leakage_stats.items():\n        if count > 0:\n            percentage = (count / len(test)) * 100\n            print(f\"{target}: {count} ({percentage:.1f}%)\")\n\n# Display final sample\nprint(f\"\\n Final submission preview:\")\ndisplay(submission_final.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:46:46.159532Z","iopub.execute_input":"2025-07-17T06:46:46.160213Z","iopub.status.idle":"2025-07-17T06:46:46.170650Z","shell.execute_reply.started":"2025-07-17T06:46:46.160191Z","shell.execute_reply":"2025-07-17T06:46:46.169957Z"}},"outputs":[{"name":"stdout","text":"\n Data leakage handled:\nTotal exact matches: 2\nTg: 2 (66.7%)\n\n Final submission preview:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"           id          Tg       FFV        Tc   Density         Rg\n0  1109053969  163.403503  0.379260  0.170384  1.118323  25.059658\n1  1422188626  153.000000  0.379027  0.217572  1.089272  20.681328\n2  2032016830  142.000000  0.350825  0.245006  1.097334  20.486364","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Tg</th>\n      <th>FFV</th>\n      <th>Tc</th>\n      <th>Density</th>\n      <th>Rg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1109053969</td>\n      <td>163.403503</td>\n      <td>0.379260</td>\n      <td>0.170384</td>\n      <td>1.118323</td>\n      <td>25.059658</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1422188626</td>\n      <td>153.000000</td>\n      <td>0.379027</td>\n      <td>0.217572</td>\n      <td>1.089272</td>\n      <td>20.681328</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2032016830</td>\n      <td>142.000000</td>\n      <td>0.350825</td>\n      <td>0.245006</td>\n      <td>1.097334</td>\n      <td>20.486364</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"def scaling_error(labels, preds, property_name):\n    \"\"\"Calculate scaled absolute error for a property\"\"\"\n    error = np.abs(labels - preds)\n    min_val, max_val = MINMAX_DICT[property_name]\n    label_range = max_val - min_val\n    return np.mean(error / label_range)\n\ndef get_property_weights(labels_df):\n    \"\"\"Calculate property weights based on sample count\"\"\"\n    property_weights = []\n    for property_name in MINMAX_DICT.keys():\n        valid_num = np.sum(labels_df[property_name].notna())\n        property_weights.append(valid_num)\n    \n    property_weights = np.array(property_weights)\n    property_weights = np.sqrt(1 / property_weights)\n    return (property_weights / np.sum(property_weights)) * len(property_weights)\n\ndef wmae_score(solution_df, submission_df):\n    \"\"\"Calculate weighted Mean Absolute Error (wMAE) competition score\"\"\"\n    chemical_properties = list(MINMAX_DICT.keys())\n    property_maes = []\n    property_weights = get_property_weights(solution_df[chemical_properties])\n    \n    for i, property_name in enumerate(chemical_properties):\n        is_labeled = solution_df[property_name].notna()\n        \n        if np.any(is_labeled):\n            mae_val = scaling_error(\n                solution_df.loc[is_labeled, property_name],\n                submission_df.loc[is_labeled, property_name], \n                property_name\n            )\n            property_maes.append(mae_val)\n        else:\n            property_maes.append(0.0)\n    \n    if not property_maes or np.sum(property_weights) == 0:\n        return float('inf')\n    \n    return float(np.average(property_maes, weights=property_weights))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:46:51.837930Z","iopub.execute_input":"2025-07-17T06:46:51.838451Z","iopub.status.idle":"2025-07-17T06:46:51.845045Z","shell.execute_reply.started":"2025-07-17T06:46:51.838431Z","shell.execute_reply":"2025-07-17T06:46:51.844214Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# Perform out-of-fold validation\n\ndef validate_model_performance():\n    oof_df = train[['SMILES'] + CFG.TARGETS].copy()\n\n    for target in CFG.TARGETS:\n        oof_df[f'{target}_preds'] = np.nan\n\n    for target in CFG.TARGETS:\n        if target not in models or target not in results:\n            print(f'skipping {target}, no trained model found!')\n\n        target_df = train[train[target].notnull()].reset_index(drop=True)\n\n        model_features = results[target]['features']\n        X_raw = target_df[model_features].values\n        y = target_df[target].values\n        groups = target_df['SMILES'].factorize()[0]\n\n        X_clean = np.nan_to_num(X_raw, nan=0.0, posinf=0.0, neginf=0.0)\n\n        group_kfold = GroupKFold(n_splits = CFG.FOLDS)\n        oof_preds = np.zeros(len(target_df))\n        fold_scores = []\n\n        for fold, (train_idx, val_idx) in enumerate(group_kfold.split(X_clean, y, groups=groups)):\n            params = results[target]['best_params']\n            \n            X_train_fold = X_clean[train_idx]\n            y_train_fold = y[train_idx]\n            X_valid_fold = X_clean[val_idx]\n            y_valid_fold = y[val_idx]\n\n            dtrain = xgb.DMatrix(X_train_fold, label=y_train_fold, missing=0.0)\n            dvalid = xgb.DMatrix(X_valid_fold, label=y_valid_fold, missing=0.0)\n\n            fold_model = xgb.train(\n                params,\n                dtrain,\n                num_boost_round = CFG.MAX_ITERATIONS,\n                evals = [(dtrain, 'train'), (dvalid, 'valid')],\n                early_stopping_rounds = CFG.EARLY_STOPPING,\n                verbose_eval = False\n            )\n\n            fold_preds = fold_model.predict(dvalid)\n            oof_preds[val_idx] = fold_preds\n\n            fold_mae = mean_absolute_error(y_valid_fold, fold_preds)\n            fold_scores.append(fold_mae)\n\n        target_indices = target_df.index\n        oof_df.loc[target_indices, f'{target}_preds'] = oof_preds\n\n        oof_mae = mean_absolute_error(y, oof_preds)\n        print(f'for {target}, oof_mae is {oof_mae:.5f}, average fold mae is {np.mean(fold_mae):.5f}')\n\n    return oof_df\n\n\n# Generate OOF predictions\ntry:\n    oof_results = validate_model_performance()\n    validation_successful = True\nexcept Exception as e:\n    print(f\"Validation failed: {str(e)[:200]}\")\n    print(\"Continuing without validation...\")\n    validation_successful = False\n    oof_results = None\n\nif validation_successful and oof_results is not None:\n    print(f\"\\n Calculating wMAE score\")\n    val_solution = oof_results[CFG.TARGETS].copy()\n    val_submission = oof_results[[f'{target}_pred' for target in CFG.TARGETS if f'{target}_pred' in oof_results.columns]].copy()\n\n    # Ensure we have predictions for all targets\n    missing_preds = []\n    for target in CFG.TARGETS:\n        if f'{target}_pred' not in val_submission.columns:\n            val_submission[f'{target}_pred'] = 0.0\n            missing_preds.append(target)\n\n    if missing_preds:\n        print(f\"Using zeros for missing predictions: {missing_preds}\")\n    \n    val_submission.columns = CFG.TARGETS\n\n    val_wmae = wmae_score(val_solution, val_submission)\n    print(f\"validation mae: {val_wmae}\")\n\n# Individual target MAEs for validation (if available)\nif validation_successful and oof_results is not None:\n    print(f\"\\n Individual target performance (validation):\")\n    for target in CFG.TARGETS:\n        pred_col = f'{target}_pred'\n        if pred_col in oof_results.columns:\n            mask = oof_results[target].notna() & oof_results[pred_col].notna()\n            if mask.sum() > 0:\n                target_mae = mean_absolute_error(\n                    oof_results.loc[mask, target],\n                    oof_results.loc[mask, pred_col]\n                )\n                samples = mask.sum()\n                print(f\"{target}: MAE = {target_mae:.5f} ({samples:,} samples)\")\n            else:\n                print(f\"{target}: No valid predictions for validation\")\n        else:\n            print(f\"{target}: No predictions generated\")\n\n# Analyze feature importance\nif models and results:\n    print(f\"\\n Analyzing feature importance...\")\n    importance_summary = {}\n    \n    for target in models:\n        if target in results:\n            model = models[target]\n            feature_names = results[target]['features']\n\n            importance_scores = model.get_score(importance_type='gain')\n            feature_importance = []\n            for i, feature in enumerate(feature_names):\n                score = importance_scores.get(f'f{i}', 0)\n                feature_importance.append((feature, score))\n\n            feature_importance.sort(key=lambda x: x[1], reverse=True)\n            importance_summary[target] = feature_importance[:20]\n\n            print(f\"\\n   {target} - Top 10 features:\")\n            for feat, score in feature_importance[:10]:\n                print(f\"{feat}: {score:.2f}\")\n\nprint(f\"\\n Validation and analysis complete!\")\nif val_wmae is not None:\n    print(f\"Estimated competition score: {val_wmae:.5f}\")\nelse:\n    print(f\"No validation score available\")\n\n# Training summary\nif results:\n    print(f\"\\n Training Summary:\")\n    for target, result in results.items():\n        print(f\"{target}: CV={result['cv_mae']:.5f}, Features={len(result['features'])}, Samples={result['n_samples']:,}\")\nelse:\n    print(f\"\\n No training results available\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T07:31:14.024289Z","iopub.execute_input":"2025-07-17T07:31:14.025061Z","iopub.status.idle":"2025-07-17T07:34:01.189937Z","shell.execute_reply.started":"2025-07-17T07:31:14.025034Z","shell.execute_reply":"2025-07-17T07:34:01.189103Z"}},"outputs":[{"name":"stdout","text":"for Tg, oof_mae is 24.70921, average fold mae is 24.73201\nfor FFV, oof_mae is 0.00590, average fold mae is 0.00589\nfor Tc, oof_mae is 0.03171, average fold mae is 0.03920\nfor Density, oof_mae is 0.03688, average fold mae is 0.03681\nfor Rg, oof_mae is 1.63651, average fold mae is 1.53077\n\n Calculating wMAE score\nUsing zeros for missing predictions: ['Tg', 'FFV', 'Tc', 'Density', 'Rg']\nvalidation mae: 0.6617991098688834\n\n Individual target performance (validation):\nTg: No predictions generated\nFFV: No predictions generated\nTc: No predictions generated\nDensity: No predictions generated\nRg: No predictions generated\n\n Analyzing feature importance...\n\n   Tg - Top 10 features:\nnum_cycles: 2024716.25\nRingCount: 1129744.25\nmorgan_226: 435984.00\nmorgan_587: 317521.47\nmorgan_887: 309777.38\nmorgan_80: 185391.30\nfr_bicyclic: 73165.26\nmorgan_807: 64554.79\nmorgan_650: 56519.56\nmorgan_74: 56180.79\n\n   FFV - Top 10 features:\nmorgan_807: 0.09\nmorgan_128: 0.05\nmorgan_587: 0.05\nmorgan_753: 0.02\nnum_cycles: 0.02\nmorgan_792: 0.02\nmorgan_378: 0.01\nmorgan_939: 0.01\nMolLogP: 0.01\nmorgan_33: 0.01\n\n   Tc - Top 10 features:\nmorgan_119: 0.07\nfr_unbrch_alkane: 0.07\nmorgan_887: 0.06\nmorgan_158: 0.05\nfr_alkyl_halide: 0.04\nfr_NH1: 0.03\nmorgan_114: 0.03\nmorgan_659: 0.03\nSMR_VSA5: 0.02\nmorgan_998: 0.02\n\n   Density - Top 10 features:\nVSA_EState1: 0.29\nNumHeteroatoms: 0.17\nSMR_VSA5: 0.15\nmorgan_849: 0.13\nSlogP_VSA12: 0.12\nfr_Ar_OH: 0.12\nmorgan_857: 0.12\nmorgan_226: 0.12\nSlogP_VSA11: 0.10\nVSA_EState7: 0.10\n\n   Rg - Top 10 features:\nNumUnspecifiedAtomStereoCenters: 771.53\nNumAtomStereoCenters: 624.00\nmorgan_33: 142.78\nfr_alkyl_halide: 138.71\nmorgan_891: 132.50\nmorgan_247: 121.17\nmorgan_591: 100.94\nmorgan_389: 88.90\nmorgan_294: 85.85\nmorgan_93: 78.41\n\n Validation and analysis complete!\nEstimated competition score: 0.66180\n\n Training Summary:\nTg: CV=24.70822, Features=461, Samples=8,244\nFFV: CV=0.00590, Features=464, Samples=7,030\nTc: CV=0.03154, Features=323, Samples=866\nDensity: CV=0.03687, Features=326, Samples=1,247\nRg: CV=1.62229, Features=320, Samples=614\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}